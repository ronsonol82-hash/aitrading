# telegram_scraper.py
import asyncio
import os
import re
import json
import pandas as pd
from datetime import datetime, timedelta
from telethon import TelegramClient
from telethon.tl.functions.messages import GetHistoryRequest
from transformers import pipeline
import torch
import redis

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ Redis
try:
    from config import Config
except ImportError:
    # –ó–∞–≥–ª—É—à–∫–∞, –µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –ø—Ä–æ–µ–∫—Ç–∞
    class Config:
        USE_REDIS = True
        REDIS_HOST = 'localhost'
        REDIS_PORT = 6379

# --- –ö–õ–Æ–ß–ò ---
# –ë–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞, –µ—Å–ª–∏ –æ–Ω –∑–∞–≥—Ä—É–∑–∏–ª—Å—è, –∏–ª–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
API_ID = getattr(Config, 'TG_API_ID', os.getenv('TELEGRAM_API_ID'))
API_HASH = getattr(Config, 'TG_API_HASH', os.getenv('TELEGRAM_API_HASH'))

if not API_ID or not API_HASH:
    raise ValueError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã API_ID –∏–ª–∏ API_HASH! –ü—Ä–æ–≤–µ—Ä—å .env –∏–ª–∏ config.py")

CHANNELS = [
    'tree_of_alpha', 'unusual_whales', 'WatcherGuru', 'Tier10k', 'WalterBloomberg',
    'Cointelegraph', 'CryptoTownEU'
]

OUTPUT_FILE = 'data_cache/news_sentiment.csv'
RAW_FILE = 'data_cache/news_raw_bert.csv'
DAYS_BACK = 100 # –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏ –≥—Ä—É–∑–∏—Ç—å (—É–º–µ–Ω—å—à–∏–ª –¥–µ—Ñ–æ–ª—Ç –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø AI ---
# –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU
device = 0 if torch.cuda.is_available() else -1
device_name = torch.cuda.get_device_name(0) if device == 0 else "CPU"
print(f"üß† –ó–∞–≥—Ä—É–∑–∫–∞ FinBERT –Ω–∞ {device_name}...")

# truncation=True –∏ max_length=512 —Å–ø–∞—Å–∞—é—Ç –æ—Ç –æ—à–∏–±–æ–∫ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
sentiment_pipeline = pipeline(
    "sentiment-analysis", 
    model="ProsusAI/finbert", 
    device=device
)

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø REDIS ---
redis_client = None
if Config.USE_REDIS:
    try:
        redis_client = redis.Redis(host=Config.REDIS_HOST, port=Config.REDIS_PORT, db=0)
        redis_client.ping()
        print("‚ö° Redis –ø–æ–¥–∫–ª—é—á–µ–Ω.")
    except Exception as e:
        print(f"‚ö†Ô∏è Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

def clean_text(text):
    if not text: return ""
    # –£–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏
    text = re.sub(r'http\S+', '', text)
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def get_bert_sentiment_batch(texts, batch_size=16):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –ø–∞—á–∫–æ–π.
    batch_size=16 –∏–ª–∏ 32 - –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–≤–æ–µ–π VRAM. 
    –ï—Å–ª–∏ –≤—ã–ª–µ—Ç–∏—Ç CUDA OOM, —É–º–µ–Ω—å—à–∞–π –¥–æ 8.
    """
    clean_texts = [t[:512] for t in texts] # –û–±—Ä–µ–∑–∞–µ–º –ø–æ –¥–ª–∏–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤ BERT
    results = []
    
    # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞
    if not clean_texts:
        return []

    try:
        # Pipeline —Å–∞–º —É–º–µ–µ—Ç –≤ –±–∞—Ç—á–∏, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞—Ç—å —Å–ø–∏—Å–æ–∫
        predictions = sentiment_pipeline(clean_texts, truncation=True, batch_size=batch_size)
        
        for p in predictions:
            score = p['score']
            if p['label'] == 'negative':
                score = -score
            elif p['label'] == 'neutral':
                score = 0.0
            results.append(score)
            
    except Exception as e:
        print(f"üî• GPU Batch Error: {e}")
        # Fallback: –µ—Å–ª–∏ –±–∞—Ç—á —É–ø–∞–ª, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–∏
        return [0.0] * len(texts)
        
    return results

async def scrape_channel(client, channel_name, cutoff_date):
    print(f"   üïµÔ∏è‚Äç‚ôÇÔ∏è –ö–∞–Ω–∞–ª: @{channel_name}...")
    
    # –°—é–¥–∞ –∫–æ–ø–∏–º –≥–æ—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    final_data = []
    
    offset_id = 0
    limit = 100 # –°–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –¢–µ–ª–µ–≥–∏ –∑–∞ —Ä–∞–∑
    consecutive_old_messages = 0
    
    while True:
        try:
            history = await client(GetHistoryRequest(
                peer=channel_name, offset_id=offset_id, offset_date=None, 
                add_offset=0, limit=limit, max_id=0, min_id=0, hash=0
            ))
            
            if not history.messages: 
                break
            
            # 1. –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º "—Å—ã—Ä—ã–µ" –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∫—É—Å–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏
            batch_candidates = [] 
            
            for message in history.messages:
                if not message.date: continue
                msg_date = message.date.replace(tzinfo=None)
                
                if msg_date < cutoff_date:
                    consecutive_old_messages += 1
                    if consecutive_old_messages > 5: # –î–∞–µ–º —à–∞–Ω—Å 5 —Å—Ç–∞—Ä—ã–º —Å–æ–æ–±—â–µ–Ω–∏—è–º (–≤–¥—Ä—É–≥ –ø–∏–Ω—ã)
                        return final_data
                    continue 
                else:
                    consecutive_old_messages = 0 # –°–±—Ä–æ—Å, –µ—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–≤–µ–∂–µ–µ

                if message.message:
                    text = clean_text(message.message)
                    if len(text) >= 10: # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π
                        batch_candidates.append({
                            'datetime': msg_date,
                            'text': text,
                            'channel': channel_name
                        })

            # 2. –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç—ã, –ø—Ä–æ–≥–æ–Ω—è–µ–º –∏—Ö —á–µ—Ä–µ–∑ BERT –æ–¥–Ω–æ–π –ø–∞—á–∫–æ–π
            if batch_candidates:
                texts_to_process = [item['text'] for item in batch_candidates]
                
                # --- GPU BLAST ---
                scores = get_bert_sentiment_batch(texts_to_process, batch_size=32)
                
                # 3. –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                for i, item in enumerate(batch_candidates):
                    score = scores[i]
                    
                    # –§–∏–ª—å—Ç—Ä —à—É–º–∞
                    if abs(score) > Config.MIN_EDGE: # –ë–µ—Ä–µ–º –ø–æ—Ä–æ–≥ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ 0.01
                        entry = item.copy()
                        entry['sentiment'] = score
                        # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞–º –Ω–µ –Ω—É–∂–µ–Ω –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏
                        entry['text'] = entry['text'][:100] 
                        
                        final_data.append(entry)

                        # --- REDIS PUSH ---
                        # –ü–∏—à–µ–º –≤ Redis, –µ—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å —Å–≤–µ–∂–∞—è (24—á)
                        if Config.USE_REDIS and redis_client:
                            if (datetime.now() - entry['datetime']).days < 1:
                                redis_entry = entry.copy()
                                redis_entry['datetime'] = str(redis_entry['datetime'])
                                try:
                                    redis_client.lpush("news_sentiment", json.dumps(redis_entry))
                                    redis_client.ltrim("news_sentiment", 0, 500)
                                except Exception as e:
                                    print(f"Redis Error: {e}")

            # –û–±–Ω–æ–≤–ª—è–µ–º offset –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ API –¢–µ–ª–µ–≥—Ä–∞–º–∞
            offset_id = history.messages[-1].id
            
            # –ü–∞—É–∑–∞, —á—Ç–æ–±—ã –î—É—Ä–æ–≤ –Ω–µ –∑–∞–±–∞–Ω–∏–ª
            await asyncio.sleep(0.5)

        except Exception as e:
            print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å {channel_name}: {e}")
            break
            
    return final_data

async def main():
    print(f"üöÄ –ó–∞–ø—É—Å–∫ News Hunter v3.0 (GPU + Redis)")
    if not os.path.exists('data_cache'): os.makedirs('data_cache')

    client = TelegramClient('anon_session', API_ID, API_HASH)
    await client.start()
    
    cutoff_date = datetime.now() - timedelta(days=DAYS_BACK)
    cutoff_date = cutoff_date.replace(tzinfo=None)
    
    all_news = []
    for channel in CHANNELS:
        news = await scrape_channel(client, channel, cutoff_date)
        print(f"    ‚úÖ {channel}: {len(news)} –∑–∞–ø–∏—Å–µ–π.")
        all_news.extend(news)
        
    if not all_news: 
        print("‚ùå –ù–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")
        return

    print(f"\nüíæ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df = pd.DataFrame(all_news)
    df.set_index('datetime', inplace=True)
    df.sort_index(inplace=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (–ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
    df.to_csv(RAW_FILE)
    
    # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞ (–∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ 15 –º–∏–Ω—É—Ç)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º mean() –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∑–∞ 15 –º–∏–Ω—É—Ç
    df_resampled = df['sentiment'].resample('15min').mean().fillna(0)
    
    # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ EMA (Exponential Moving Average), —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å —Ä–µ–∑–∫–∏–µ –ø–∏–∫–∏
    df_resampled_ema = df_resampled.ewm(span=12).mean() # 3 —á–∞—Å–∞
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ç–æ—Ä—ã–π –∂–¥–µ—Ç data_loader.py
    final_df = pd.DataFrame({
        'sentiment': df_resampled,
        'sentiment_ema': df_resampled_ema
    })
    
    final_df.to_csv(OUTPUT_FILE)
    print(f"üéâ –ì–æ—Ç–æ–≤–æ! \n   –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ: {RAW_FILE} \n   –î–ª—è –±–æ—Ç–∞: {OUTPUT_FILE}")

if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüõë –°–∫—Ä–∞–ø–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")