# indicators.py
import pandas as pd
import numpy as np
from numba import njit
from features_lib import StructureFeatures  # <--- –í–ê–ñ–ù–û: –ò–º–ø–æ—Ä—Ç –Ω–æ–≤–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏

# --- NUMBA –î–õ–Ø –†–ê–ó–ú–ï–¢–ö–ò (Triple Barrier) ---
# –û—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä—ã–π Labeling —Ç–æ–ª—å–∫–æ –¥–ª—è —Ü–µ–ª–µ–π –æ–±—É—á–µ–Ω–∏—è (Target),
# –Ω–æ —Å–∞–º–∏ —Ñ–∏—á–∏ (Features) —Ç–µ–ø–µ—Ä—å —Å—á–∏—Ç–∞—é—Ç—Å—è –≤ features_lib.

@njit
def triple_barrier_numba(closes, highs, lows, atrs, look_ahead, rr_ratio):
    n = len(closes)
    labels = np.zeros(n, dtype=np.int32) 
    
    for i in range(n - look_ahead):
        entry = closes[i]
        vol = atrs[i]
        if vol == 0: continue

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ü–µ–ª–∏
        tp_dist = vol * rr_ratio
        sl_dist = vol * 1.0 
        
        tp_long = entry + tp_dist
        sl_long = entry - sl_dist
        tp_short = entry - tp_dist
        sl_short = entry + sl_dist
        
        long_res = 0
        short_res = 0
        
        for j in range(1, look_ahead + 1):
            idx = i + j
            if idx >= n: break
            
            # –õ–æ–≥–∏–∫–∞ Long
            if long_res == 0:
                hit_sl = lows[idx] <= sl_long
                hit_tp = highs[idx] >= tp_long
                if hit_sl and hit_tp: long_res = -1 
                elif hit_sl: long_res = -1
                elif hit_tp: long_res = 1
            
            # –õ–æ–≥–∏–∫–∞ Short
            if short_res == 0:
                hit_sl = highs[idx] >= sl_short
                hit_tp = lows[idx] <= tp_short
                if hit_sl and hit_tp: short_res = -1
                elif hit_sl: short_res = -1
                elif hit_tp: short_res = 1
            
            if long_res != 0 and short_res != 0: break
            
        if long_res == 1 and short_res != 1:
            labels[i] = 1 # LONG
        elif short_res == 1 and long_res != 1:
            labels[i] = 2 # SHORT
            
    return labels

# --- –ö–õ–ê–°–°-–ê–î–ê–ü–¢–ï–† ---
    
class FeatureEngineer:
    
    @staticmethod
    def add_features(df):
        """
        –ü–ï–†–ï–•–í–ê–¢–ß–ò–ö: –í–º–µ—Å—Ç–æ —Å—Ç–∞—Ä—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤—ã–∑—ã–≤–∞–µ–º StructureFeatures.
        """
        if df is None or df.empty:
            # –ù–µ—á–µ–≥–æ —Å—á–∏—Ç–∞—Ç—å ‚Äî —Å—Ä–∞–∑—É –≤—ã—Ö–æ–¥–∏–º.
            return df

        print("   üèóÔ∏è [STRUCTURE] Calculating Confluence Scores...") 
        # –í—ã–∑—ã–≤–∞–µ–º –ª–æ–≥–∏–∫—É –∏–∑ features_lib.py
        return StructureFeatures.process_all(df)

    @staticmethod
    def add_htf_features(df_ltf, df_htf):
        """
        –ú–µ—Ä–¥–∂ —Å—Ç–∞—Ä—à–µ–≥–æ –¢–§: –∑–∞–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—é" –∏ "–°—Ç—Ä—É–∫—Ç—É—Ä—É".
        """
        if df_htf is None or df_htf.empty: return df_ltf

        # 1. –°—á–∏—Ç–∞–µ–º —Ñ–∏—á–∏ –Ω–∞ —Å—Ç–∞—Ä—à–µ–º –¢–§ (–ø–æ–∫–∞ –æ–Ω —Ü–µ–ª–æ—Å—Ç–Ω—ã–π)
        # –í–∞–∂–Ω–æ –¥–µ–ª–∞—Ç—å copy(), —á—Ç–æ–±—ã –Ω–µ –∑–∞–º—É—Å–æ—Ä–∏—Ç—å –∫—ç—à
        df_htf_feat = StructureFeatures.process_all(df_htf.copy())
        
        # 2. –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ "–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ" —Ñ–∏—á–∏ (–ë–µ–∑ —Ü–µ–Ω!)
        cols_to_keep = [
            'volatility',    # –û–±—â–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –±–æ–ª—å–Ω–∏—Ü—ã
            'sup_strength',  # –°–∏–ª–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ 4H (—á–∏—Å–ª–æ 0..100)
            'res_strength',  # –°–∏–ª–∞ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è 4H
            'sup_dist_atr',  # –î–∏—Å—Ç–∞–Ω—Ü–∏—è –≤ ATR (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞!)
            'res_dist_atr', 
            'channel_pos',   # –ü–æ–∑–∏—Ü–∏—è –≤ –∫–∞–Ω–∞–ª–µ 0..1
            'squeeze_factor' # –°–∂–∞—Ç–∏–µ
        ]
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º, –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –∫–∞–∫–æ–π-—Ç–æ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç
        cols = [c for c in cols_to_keep if c in df_htf_feat.columns]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å htf_
        df_ready = df_htf_feat[cols].add_prefix('htf_')
        
        # 3. –ú–µ—Ä–¥–∂–∏–º (Backward direction - –±–µ–∑ –∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ)
        merged = pd.merge_asof(
            df_ltf.sort_index(),
            df_ready.sort_index(),
            left_index=True,
            right_index=True,
            direction='backward'
        )
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ (HTF –¥–∞–Ω–Ω—ã–µ —Ä–µ–¥–∫–∏–µ, –æ–Ω–∏ "—Ç—è–Ω—É—Ç—Å—è" –≤–ø–µ—Ä–µ–¥)
        return merged.fillna(method='ffill').fillna(0)

    @staticmethod
    def add_levels_distance(df, window=3):
        """
        –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å leak_test.py.
        –ß–µ—Å—Ç–Ω–æ —Å—á–∏—Ç–∞–µ—Ç dist_to_max/dist_to_min –¢–û–õ–¨–ö–û –ø–æ –ø—Ä–æ—à–ª—ã–º –±–∞—Ä–∞–º.
        """
        if df is None or df.empty:
            return df

        highs = df['high'].values.astype(np.float64)
        lows = df['low'].values.astype(np.float64)
        closes = df['close'].values.astype(np.float64)

        if 'atr' in df.columns:
            atrs = df['atr'].values.astype(np.float64)
        else:
            # –ø—Ä–æ—Å—Ç–æ–π fallback, —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞—Ç—å
            atrs = np.ones_like(closes, dtype=np.float64)

        n = len(df)
        dist_to_max = np.zeros(n, dtype=np.float64)
        dist_to_min = np.zeros(n, dtype=np.float64)

        for i in range(n):
            if i < window:
                # –∏—Å—Ç–æ—Ä–∏–∏ –º–∞–ª–æ ‚Äî —Å—á–∏—Ç–∞–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –Ω—É–ª–µ–≤—ã–º
                dist_to_max[i] = 0.0
                dist_to_min[i] = 0.0
                continue

            prev_high = np.max(highs[i-window:i])
            prev_low = np.min(lows[i-window:i])
            atr_val = atrs[i] if atrs[i] > 0 else 1.0

            # –í–ê–ñ–ù–û: —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–µ–¥—à–∏–µ –±–∞—Ä—ã, –±–µ–∑ –∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤–ø–µ—Ä—ë–¥
            dist_to_max[i] = (prev_high - closes[i]) / atr_val
            dist_to_min[i] = (prev_low - closes[i]) / atr_val

        df_out = df.copy()
        df_out['dist_to_max'] = dist_to_max
        df_out['dist_to_min'] = dist_to_min
        return df_out

    @staticmethod
    def label_data(df, look_ahead, rr_ratio):
        """
        –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É—á–∏—Ç–µ–ª—è (Supervised Learning).
        """
        closes = df['close'].values.astype(np.float64)
        highs = df['high'].values.astype(np.float64)
        lows = df['low'].values.astype(np.float64)
        atrs = df['atr'].fillna(0).values.astype(np.float64)
        
        labels = triple_barrier_numba(closes, highs, lows, atrs, int(look_ahead), float(rr_ratio))
        
        df_labeled = df.copy()
        df_labeled['target'] = labels
        return df_labeled.iloc[:-int(look_ahead)]