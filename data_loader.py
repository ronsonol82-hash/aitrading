# data_loader.py
import pandas as pd
import requests
import time
import os
import numpy as np
import redis
import json
from datetime import datetime, timedelta
from config import Config
from brokers import get_broker
from indicators import FeatureEngineer

class DataLoader:
    CACHE_DIR = "data_cache"
    NEWS_FILE = "data_cache/news_sentiment.csv"
    
    def __init__(self):
        self.redis_client = None
        if Config.USE_REDIS:
            try:
                self.redis_client = redis.Redis(host=Config.REDIS_HOST, port=Config.REDIS_PORT, db=0)
                self.redis_client.ping()
                print("üß† [DATA] Redis –ø–æ–¥–∫–ª—é—á–µ–Ω.")
            except:
                print("‚ö†Ô∏è [DATA] Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –†–∞–±–æ—Ç–∞–µ–º —Å —Ñ–∞–π–ª–∞–º–∏.")
    
    @staticmethod
    def _ensure_cache_dir():
        if not os.path.exists(DataLoader.CACHE_DIR):
            os.makedirs(DataLoader.CACHE_DIR)

    @staticmethod
    def get_funding_history(symbol, start_ts, end_ts):
        base_url = "https://fapi.binance.com/fapi/v1/fundingRate"
        all_funding = []
        current_start = start_ts
        
        print(f"   üí∏ [FUNDING] –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞–≤–∫–∏ –¥–ª—è {symbol}...")
        
        while current_start < end_ts:
            params = {
                'symbol': symbol,
                'startTime': current_start,
                'endTime': end_ts,
                'limit': 1000
            }
            try:
                r = requests.get(base_url, params=params, timeout=5)
                if r.status_code != 200:
                    break
                data = r.json()
                if not data: break
                
                all_funding.extend(data)
                current_start = data[-1]['fundingTime'] + 1
                time.sleep(0.05)
            except:
                break
                
        if not all_funding:
            return pd.DataFrame()
            
        df = pd.DataFrame(all_funding)
        df['fundingRate'] = df['fundingRate'].astype(float)
        df['datetime'] = pd.to_datetime(df['fundingTime'], unit='ms')
        df.set_index('datetime', inplace=True)
        return df[['fundingRate']]

    @staticmethod
    def get_binance_data(symbol, start_date, end_date, interval):
        endpoints = [
            ("Futures Global", "https://fapi.binance.com/fapi/v1/klines"),
            ("Spot Global", "https://api.binance.com/api/v3/klines")
        ]

        start_ts = int(start_date.timestamp() * 1000)
        end_ts = int(end_date.timestamp() * 1000)
        
        df_candles = pd.DataFrame()
        
        for region, base_url in endpoints:
            print(f"üì• [BINANCE {region}] –ó–∞–≥—Ä—É–∑–∫–∞ {symbol}...")
            
            all_candles = []
            current_start = start_ts
            failed = False
            
            while current_start < end_ts:
                params = {
                    'symbol': symbol,
                    'interval': interval,
                    'startTime': current_start,
                    'endTime': end_ts,
                    'limit': 1500
                }
                
                try:
                    response = requests.get(base_url, params=params, timeout=5)
                    if response.status_code != 200:
                        failed = True; break
                    
                    data = response.json()
                    if not data: break
                        
                    all_candles.extend(data)
                    current_start = data[-1][6] + 1
                    time.sleep(0.05)
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {region}: {e}")
                    failed = True; break
            
            if not failed and all_candles:
                df = pd.DataFrame(all_candles, columns=[
                    'timestamp', 'open', 'high', 'low', 'close', 'volume', 
                    'close_time', 'q_vol', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'
                ])
                
                cols = ['open', 'high', 'low', 'close', 'volume', 'taker_buy_base']
                df[cols] = df[cols].astype(float)
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
                df.set_index('datetime', inplace=True)
                
                df_candles = df
                print(f"‚úÖ –°–≤–µ—á–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)}")
                break

        if df_candles.empty:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏.")
            return pd.DataFrame()

        taker_buy = df_candles['taker_buy_base']
        total_vol = df_candles['volume']
        taker_sell = total_vol - taker_buy
        df_candles['imbalance'] = (taker_buy - taker_sell) / total_vol.replace(0, 1)
        
        try:
            df_funding = DataLoader.get_funding_history(symbol, start_ts, end_ts)
            if not df_funding.empty:
                df_candles = df_candles.sort_index()
                df_funding = df_funding.sort_index()
                combined = pd.merge_asof(
                    df_candles, 
                    df_funding, 
                    left_index=True, 
                    right_index=True, 
                    direction='backward'
                )
                combined['fundingRate'] = combined['fundingRate'].fillna(method='bfill').fillna(0)
                df_candles['funding_rate'] = combined['fundingRate']
            else:
                df_candles['funding_rate'] = 0.0
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–µ—Ä–¥–∂–∞ —Ñ–∞–Ω–¥–∏–Ω–≥–∞: {e}")
            df_candles['funding_rate'] = 0.0

        return df_candles[['open', 'high', 'low', 'close', 'volume', 'taker_buy_base', 'funding_rate', 'imbalance']]
    
    @staticmethod
    def get_exchange_data(symbol, start_date, end_date, interval):
        """
        –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–≤–µ—á–µ–π —Å –±–∏—Ä–∂–∏.

        –õ–æ–≥–∏–∫–∞:
        - —Å–º–æ—Ç—Ä–∏–º Config.ASSET_ROUTING ‚Üí –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –±—Ä–æ–∫–µ—Ä–∞;
        - –ï–°–õ–ò —Å–∏–º–≤–æ–ª –ù–ï –ø—Ä–æ–ø–∏—Å–∞–Ω —è–≤–Ω–æ ‚Üí —Å—Ä–∞–∑—É –∏—Å–ø–æ–ª—å–∑—É–µ–º Binance-—Ñ–æ–ª–ª–±—ç–∫;
        - –µ—Å–ª–∏ –±—Ä–æ–∫–µ—Ä = bitget/tinkoff, –ø—Ä–æ–±—É–µ–º –µ–≥–æ,
            –ø—Ä–∏ –æ—à–∏–±–∫–µ / –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ ‚Äî fallback –Ω–∞ Binance.
        """
        # –ë–µ—Ä—ë–º –Ø–í–ù–´–ô –º–∞—Ä—à—Ä—É—Ç, –±–µ–∑ –¥–µ—Ñ–æ–ª—Ç–∞
        broker_name = Config.ASSET_ROUTING.get(symbol, Config.DEFAULT_BROKER)
        uname = str(broker_name).lower() if broker_name else None

        # --- BITGET (–∫—Ä–∏–ø—Ç–∞, —Ç–æ–ª—å–∫–æ —è–≤–Ω–æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–∏–∫–µ—Ä—ã) ---
        if uname == "bitget":
            try:
                broker = get_broker("bitget")
                return broker.get_historical_klines(
                    symbol=symbol,
                    interval=interval,
                    start=start_date,
                    end=end_date,
                )
            except Exception as e:
                print(f"‚ö†Ô∏è [DATA] Bitget failed for {symbol}, fallback to Binance: {e}")
                return DataLoader.get_binance_data(symbol, start_date, end_date, interval)

        # --- TINKOFF (–∞–∫—Ü–∏–∏ –ú–û–ï–•, —Ç–æ–∂–µ —Ç–æ–ª—å–∫–æ —è–≤–Ω–æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ) ---
        if uname == "tinkoff":
            print(f"üì• [TINKOFF] –ó–∞–≥—Ä—É–∑–∫–∞ {symbol}...")
            try:    
                broker = get_broker("tinkoff")
                return broker.get_historical_klines(
                    symbol=symbol,
                    interval=interval,
                    start=start_date,
                    end=end_date,
                )
            except Exception as e:
                print(f"‚ö†Ô∏è [DATA] Tinkoff failed for {symbol}, fallback to Binance: {e}")
                return DataLoader.get_binance_data(symbol, start_date, end_date, interval)

        # --- –í–°–Å –û–°–¢–ê–õ–¨–ù–û–ï ‚Üí Binance –∫–∞–∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç–∞–≤—â–∏–∫ –∏—Å—Ç–æ—Ä–∏–∏ ---
        return DataLoader.get_binance_data(symbol, start_date, end_date, interval)

    def load_news_sentiment(self):
        if self.redis_client:
            try:
                cached = self.redis_client.lrange("news_sentiment", 0, -1)
                if cached:
                    data = [json.loads(x) for x in cached]
                    df = pd.DataFrame(data)
                    df['datetime'] = pd.to_datetime(df['datetime'])
                    df.set_index('datetime', inplace=True)
                    try:
                        # –†–µ—Å–µ–º–ø–ª–∏–º –ø–æ–¥ –∫–æ–Ω—Ñ–∏–≥ (1h –∏–ª–∏ 15m)
                        return df.resample(Config.TIMEFRAME_LTF)['sentiment'].mean().to_frame()
                    except: return None
            except: pass

        if not os.path.exists(DataLoader.NEWS_FILE): return None
        try:
            df_news = pd.read_csv(DataLoader.NEWS_FILE, index_col='datetime', parse_dates=True)
            df_news['sentiment_ema'] = df_news['sentiment'].ewm(span=12).mean()
            return df_news[['sentiment', 'sentiment_ema']]
        except: return None

    @staticmethod
    def _fetch_and_cache(symbol, start_date, end_date, interval):
        DataLoader._ensure_cache_dir()
        safe_symbol = symbol.replace("-", "").replace("/", "")
        
        # v7 - –≤–µ—Ä—Å–∏—è –∫—ç—à–∞ –¥–ª—è 1H/4H
        filename = f"{DataLoader.CACHE_DIR}/{safe_symbol}_{interval}_v7_WAR.csv"
        
        if os.path.exists(filename):
            try:
                df = pd.read_csv(filename, index_col='datetime', parse_dates=True)
                if len(df) > 100:
                    mask = (df.index >= start_date) & (df.index <= end_date)
                    if len(df.loc[mask]) > 0: return df.loc[mask]
            except: pass 
        
        # üëâ –∑–¥–µ—Å—å –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ –±–∏–Ω–∞–Ω—Å–∞ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –º–µ—Ç–æ–¥
        df = DataLoader.get_exchange_data(safe_symbol, start_date, end_date, interval)
        if not df.empty:
            df.to_csv(filename)
        return df

    @staticmethod
    def merge_mtf(df_ltf, df_htf):
        """
        –ü—Ä–æ–∫–∏–¥—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç–∞—Ä—à–µ–≥–æ –¢–§ –≤ –º–ª–∞–¥—à–∏–π.

        –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∏–∑ FeatureEngineer.add_htf_features:
        - —Å—á–∏—Ç–∞–µ–º —É—Ä–æ–≤–Ω–∏/–∫–∞–Ω–∞–ª/squeeze –Ω–∞ HTF;
        - –º–µ—Ä–∂–∏–º –∏—Ö –≤ LTF —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º htf_;
        - –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ HTF –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –Ω—É–ª–∏.
        """
        from indicators import FeatureEngineer

        # –ï—Å–ª–∏ HTF –Ω–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞—ë–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –Ω—É–ª—è–º–∏,
        # —á—Ç–æ–±—ã UNIVERSAL_FEATURE_COLS –≤—Å–µ–≥–¥–∞ –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –≤ df.
        if df_htf is None or df_htf.empty:
            htf_cols = [
                "htf_volatility",
                "htf_sup_strength",
                "htf_res_strength",
                "htf_sup_dist_atr",
                "htf_res_dist_atr",
                "htf_channel_pos",
                "htf_squeeze_factor",
            ]
            for c in htf_cols:
                if c not in df_ltf.columns:
                    df_ltf[c] = 0.0
            return df_ltf

        df_ltf = df_ltf.sort_index()
        df_htf = df_htf.sort_index()

        try:
            # –ó–¥–µ—Å—å –≤–Ω—É—Ç—Ä–∏:
            # 1) StructureFeatures.process_all –Ω–∞ df_htf
            # 2) –≤—ã–±–æ—Ä ['volatility', 'sup_strength', ...]
            # 3) add_prefix('htf_') –∏ merge_asof –≤ LTF
            df_merged = FeatureEngineer.add_htf_features(df_ltf, df_htf)
            return df_merged
        except Exception as e:
            print(f"‚ö†Ô∏è [HTF] –û—à–∏–±–∫–∞ –ø—Ä–∏ merge_mtf: {e}")
            # –ê–≤–∞—Ä–∏–π–Ω—ã–π —Ñ–æ–ª–ª–±—ç–∫ ‚Äî —Ö–æ—Ç—è –±—ã –Ω—É–ª–∏, —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞–ª–æ –æ–±—É—á–µ–Ω–∏–µ
            htf_cols = [
                "htf_volatility",
                "htf_sup_strength",
                "htf_res_strength",
                "htf_sup_dist_atr",
                "htf_res_dist_atr",
                "htf_channel_pos",
                "htf_squeeze_factor",
            ]
            for c in htf_cols:
                if c not in df_ltf.columns:
                    df_ltf[c] = 0.0
            return df_ltf

    @staticmethod
    def get_portfolio_data(
        assets,
        leader_symbol,          # str –ò–õ–ò dict[str, str]
        start_date,
        end_date,
        interval_ltf,
        interval_htf,
    ):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ—Ä—Ç—Ñ–µ–ª—å —Å —Ñ–∏—á–∞–º–∏, –Ω–æ–≤–æ—Å—Ç—è–º–∏ –∏ –∫–æ–ª–æ–Ω–∫–æ–π leader_close.

        leader_symbol:
            - str  -> –æ–¥–∏–Ω –ª–∏–¥–µ—Ä –¥–ª—è –≤—Å–µ—Ö (—Å—Ç–∞—Ä–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)
            - dict -> {symbol: leader_symbol} –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
        """
        import pandas as pd

        dl = DataLoader()
        portfolio_data: dict[str, pd.DataFrame] = {}

        # --- 0. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–∞–ø—ã –ª–∏–¥–µ—Ä–æ–≤ ---
        if isinstance(leader_symbol, dict):
            leader_map: dict[str, str] = leader_symbol
            print(f"üëë [DATA] –õ–∏–¥–µ—Ä—ã –ø–æ –∫–ª–∞—Å—Å–∞–º: {leader_map}")
            unique_leaders = sorted(set(leader_map.values()))
            print(f"üëë [DATA] –õ–∏–¥–µ—Ä—ã —Ä—ã–Ω–∫–æ–≤: {unique_leaders} "
                f"(tickers={len(leader_map)})")
        else:
            # –°—Ç–∞—Ä—ã–π —Ä–µ–∂–∏–º: –æ–¥–∏–Ω –ª–∏–¥–µ—Ä –Ω–∞ –≤—Å–µ—Ö
            leader_map = {sym: leader_symbol for sym in assets}
            print(f"üëë [DATA] –õ–∏–¥–µ—Ä –¥–ª—è –≤—Å–µ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {leader_symbol}")

        # –ö—ç—à–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –ª–∏–¥–µ—Ä–æ–≤, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ç–∏–∫–µ—Ä –ø–æ 10 —Ä–∞–∑
        leader_cache: dict[str, pd.DataFrame] = {}

        # –ù–æ–≤–æ—Å—Ç–∏ –æ–±—â–∏–µ –¥–ª—è –≤—Å–µ—Ö
        df_news = dl.load_news_sentiment()

        for symbol in assets:
            # 1. –ú–ª–∞–¥—à–∏–π –¢–§
            df = dl._fetch_and_cache(symbol, start_date, end_date, interval_ltf)
            if df.empty:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {symbol}. –ü—Ä–æ–ø—É—Å–∫.")
                continue

            # 2. –°—Ç–∞—Ä—à–∏–π –¢–§
            df_htf = dl._fetch_and_cache(symbol, start_date, end_date, interval_htf)

            # 3. MTF merge + HTF-—Ñ–∏—á–∏
            df = dl.merge_mtf(df, df_htf)

            # 4. –õ–∏–¥–µ—Ä –¥–ª—è —ç—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            sym_leader = leader_map.get(symbol)
            if sym_leader:
                if sym_leader not in leader_cache:
                    print(f"üëë [DATA] –ó–∞–≥—Ä—É–∑–∫–∞ –ª–∏–¥–µ—Ä–∞ {sym_leader} (–¥–ª—è {symbol} –∏ –¥—Ä—É–≥–∏—Ö).")
                    leader_cache[sym_leader] = dl._fetch_and_cache(
                        sym_leader, start_date, end_date, interval_ltf
                    )

                df_leader = leader_cache.get(sym_leader, None)
            else:
                df_leader = None

            if df_leader is not None and not df_leader.empty:
                leader_cls = df_leader[["close"]].rename(columns={"close": "leader_close"})
                df = df.join(leader_cls).ffill()

                # –ï—Å–ª–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å–∞–º —è–≤–ª—è–µ—Ç—Å—è —Å–≤–æ–∏–º –ª–∏–¥–µ—Ä–æ–º
                if symbol == sym_leader:
                    df["leader_close"] = df["close"]
                else:
                    df["leader_close"] = df["leader_close"].fillna(df["close"])
            else:
                # –§–æ–ª–±—ç–∫ ‚Äì –ø—Ä–æ—Å—Ç–æ –¥—É–±–ª–∏—Ä—É–µ–º close
                df["leader_close"] = df["close"]

            # 5. –ù–æ–≤–æ—Å—Ç–∏
            if df_news is not None and not df_news.empty:
                df = df.join(df_news).fillna(0)
            else:
                df["sentiment"] = 0.0
                df["sentiment_ema"] = 0.0

            portfolio_data[symbol] = df

        if portfolio_data:
            lengths = {sym: len(df) for sym, df in portfolio_data.items()}
            min_len = min(lengths.values()) if lengths else 0
            print(
                f"‚úÖ –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã. –ê–∫—Ç–∏–≤–æ–≤: {len(portfolio_data)}, "
                f"–º–∏–Ω–∏–º—É–º –±–∞—Ä–æ–≤ –Ω–∞ –∞–∫—Ç–∏–≤: {min_len}"
            )

        return portfolio_data
