# signal_generator.py
import pandas as pd
import numpy as np
import pickle
import os
import sys
from tqdm import tqdm
from datetime import datetime, timedelta
from config import Config, UniverseMode
from data_loader import DataLoader
from indicators import FeatureEngineer
from model_engine import MLEngine
import argparse
from joblib import Parallel, delayed
import multiprocessing

# --- HELPER FOR PARALLEL TRAINING ---
def train_wrapper(sym, model_obj, data_slice, features):
    # This runs in a separate process
    try:
        model_obj.train(data_slice, features)
        return sym, model_obj
    except Exception as e:
        print(f"‚ùå Error training {sym}: {e}")
        return sym, model_obj # Return old model if failed

class UniversalSignalFactory:
    """
    –§–∞–±—Ä–∏–∫–∞ –°–∏–≥–Ω–∞–ª–æ–≤ v3.0 (Universal Brain Edition).

    –û–±—É—á–∞–µ—Ç –ï–î–ò–ù–£–Æ –º–æ–¥–µ–ª—å –Ω–∞ –æ–±—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω–µ:
      - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ—Ö —É—á–∏—Ç–µ–ª–µ–π –∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è,
      - –ø—Ä–∏–º–µ–Ω—è–µ–º –µ—ë –∫–æ –≤—Å–µ–º—É —Å–ø–∏—Å–∫—É Config.ASSETS.
    """
    OUTPUT_FILE = "data_cache/production_signals_v1.pkl"

    def __init__(
        self,
        regime_preset: str = "classic",
        cross_asset_wf: bool = False,
        train_window: int | None = None,
        trade_window: int | None = None,
        ):
        self.preset = regime_preset
        self.cross_asset_wf = cross_asset_wf
        self.train_window = train_window
        self.trade_window = trade_window

        self.data: dict[str, pd.DataFrame] = {}

        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä —Ñ–∏—á –±–µ–∑ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö —Ü–µ–Ω
        # (align —Å Config.UNIVERSAL_FEATURE_COLS)
        self.feature_cols = Config.UNIVERSAL_FEATURE_COLS

        # üß† –£—á–∏—Ç–µ–ª—è –∑–∞–≤—è–∑—ã–≤–∞–µ–º –Ω–∞ UNIVERSE_MODE + cross_asset_wf
        mode = Config.UNIVERSE_MODE

        if self.cross_asset_wf:
            # –ö—Ä–æ—Å—Å-–∞–∫—Ç–∏–≤–Ω—ã–π WF –≤–Ω—É—Ç—Ä–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –≤—Å–µ–ª–µ–Ω–Ω–æ–π
            if mode == UniverseMode.CRYPTO:
                # —Ç–æ–ª—å–∫–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã
                self.teachers = Config.crypto_symbols()
            elif mode == UniverseMode.STOCKS:
                # —Ç–æ–ª—å–∫–æ –∞–∫—Ü–∏–∏/–≤–∞–ª—é—Ç—ã –±–∏—Ä–∂–∏
                self.teachers = Config.equity_symbols()
            else:
                # BOTH: –±–µ—Ä—ë–º –≤—Å–µ –∫–ª–∞—Å—Å—ã
                self.teachers = Config.crypto_symbols() + Config.equity_symbols()
        else:
            # –ë–µ–∑ cross-asset: —É—á–∏—Ç–µ–ª—è = —Ç–µ–∫—É—â–∏–π —Ç–æ—Ä–≥–æ–≤—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å
            # (—Ç–æ, —á—Ç–æ –≤—ã–±—Ä–∞–Ω–æ —á–µ—Ä–µ–∑ UNIVERSE_MODE / GUI)
            self.teachers = ["MOEX"]

        # –ï—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å —Å—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ, –º–æ–∂–Ω–æ –≤—Ä—É—á–Ω—É—é –∑–∞–¥–∞—Ç—å –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ:
        # self.teachers = ["MOEX"] //// self.teachers = Config.ASSETS
            
    # -------- –ó–ê–ì–†–£–ó–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• --------
    def load_data(self) -> None:
        print("üèó [UNIVERSAL FACTORY] –ó–∞–≥—Ä—É–∑–∫–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
        end = datetime.now()
        # –ì–ª—É–±–æ–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (‚âà 6‚Äì7 –ª–µ—Ç)
        start = end - timedelta(days=2500)

        mode = Config.UNIVERSE_MODE
        if mode == UniverseMode.CRYPTO:
            # –¢–æ–ª—å–∫–æ –∫—Ä–∏–ø—Ç–∞
            all_assets = Config.crypto_symbols()
        elif mode == UniverseMode.STOCKS:
            # –¢–æ–ª—å–∫–æ –±–∏—Ä–∂–∞ (MOEX / –¢–∏–Ω—å–∫–æ—Ñ—Ñ)
            all_assets = Config.equity_symbols()
        else:
            # BOTH ‚Äî –æ–±—ä–µ–¥–∏–Ω—è–µ–º –¥–≤–∞ —Å–ø–∏—Å–∫–∞
            all_assets = Config.crypto_symbols() + Config.equity_symbols()

        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —É–±–µ—Ä—ë–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        all_assets = list(sorted(set(all_assets)))
        print(f"   üì• –ó–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ({mode.value}): {all_assets}")

        leader_map = {sym: Config.get_leader_for_symbol(sym) for sym in all_assets}

        self.data = DataLoader.get_portfolio_data(
            all_assets,
            leader_map,
            start,
            end,
            Config.TIMEFRAME_LTF,
            Config.TIMEFRAME_HTF,
        )

        if not self.data:
            print("‚ùå [UNIVERSAL] –û—à–∏–±–∫–∞: DataLoader –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å.")
            sys.exit(1)

        print("üõ† –†–∞—Å—á—ë—Ç —Ñ–∏—á–µ–π (price-agnostic —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ + –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è —É—Ä–æ–≤–Ω–µ–π)...")
        for sym, df in tqdm(self.data.items(), desc="Feature Engineering"):
            try:
                # 1) –§–∏—á–∏ (—É—Ä–æ–≤–Ω–∏, –∫–∞–Ω–∞–ª, –∫–æ–Ωfluence score –∏ —Ç.–¥.)
                df_feat = FeatureEngineer.add_features(df)

                # 2) –†–∞–∑–º–µ—Ç–∫–∞ triple-barrier (target)
                df_labeled = FeatureEngineer.label_data(
                    df_feat, Config.LOOK_AHEAD, Config.RR_RATIO
                )

                # Drop NaN –∏–∑-–∑–∞ —Ä–æ–ª–ª–∏–Ω–≥–æ–≤/ATR
                self.data[sym] = df_labeled.dropna()
            except Exception as e:
                print(f"‚ö†Ô∏è [UNIVERSAL] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {sym}: {e}")

        print(f"‚úÖ [UNIVERSAL] –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã. –ê–∫—Ç–∏–≤–æ–≤ –≤ –ø–∞–º—è—Ç–∏: {len(self.data)}")

    # -------- –û–ë–£–ß–ï–ù–ò–ï –ì–õ–û–ë–ê–õ–¨–ù–û–ì–û –ú–û–ó–ì–ê --------
    def run_universal_training(self) -> None:
        if not self.data:
            print("‚ùå [UNIVERSAL] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏ load_data().")
            return

        print("\nüéì [UNIVERSAL] –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –ì–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ú–æ–∑–≥–∞...")
        print(f"   üë®‚Äçüè´ –£—á–∏—Ç–µ–ª—è: {self.teachers}")
        if self.cross_asset_wf:
            print("   üåâ –†–µ–∂–∏–º: CROSS-ASSET WALK-FORWARD –≤–∫–ª—é—á–µ–Ω.")
            if self.train_window or self.trade_window:
                print(
                    f"   üìê –û–∫–Ω–∞: train_window={self.train_window}, "
                    f"trade_window={self.trade_window}"
                )
        teacher_frames: list[pd.DataFrame] = []
        min_len = float("inf")

        # 1) –°–æ–±–∏—Ä–∞–µ–º —É—á–∏—Ç–µ–ª–µ–π –∏ –Ω–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏
        for sym in self.teachers:
            if sym not in self.data:
                print(f"   ‚ö†Ô∏è –£—á–∏—Ç–µ–ª—å {sym} –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue

            df = self.data[sym]
            if len(df) < 100:
                print(f"   ‚ö†Ô∏è {sym}: —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –±–∞—Ä–æ–≤ ({len(df)}), –ø—Ä–æ–ø—É—Å–∫.")
                continue

            teacher_frames.append(df)
            if len(df) < min_len:
                min_len = len(df)

            print(f"   ‚úîÔ∏è {sym}: {len(df)} –±–∞—Ä–æ–≤ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.")

        if not teacher_frames:
            print("‚ùå [UNIVERSAL] –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —É—á–∏—Ç–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
            return

        lengths = [len(x) for x in teacher_frames]
        print(f"   üìè –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —É—á–∏—Ç–µ–ª—å—Å–∫–∏—Ö –≤—ã–±–æ—Ä–æ–∫: {lengths}")
        
        if self.cross_asset_wf:
            total_bars = min_len

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏–Ω—É train / OOS
            if self.train_window is not None and self.trade_window is not None:
                train_len = min(self.train_window, total_bars - 50)
                oos_len = min(self.trade_window, total_bars - train_len)
            elif self.train_window is not None:
                train_len = min(self.train_window, total_bars - 50)
                oos_len = total_bars - train_len
            elif self.trade_window is not None:
                oos_len = min(self.trade_window, max(50, total_bars // 3))
                train_len = total_bars - oos_len
            else:
                train_len = int(total_bars * 0.7)
                oos_len = total_bars - train_len

            if train_len <= 0:
                print("‚ùå [UNIVERSAL-CA] –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –æ–∫–Ω–∞ train/test. "
                      "–£–º–µ–Ω—å—à–∏ trade_window –∏–ª–∏ —É–≤–µ–ª–∏—á—å train_window.")
                return

            print(
                f"   üß™ [CA-WF] –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ {train_len} –±–∞—Ä–æ–≤ —É—á–∏—Ç–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è "
                f"–∏ –æ—Ç–∫–ª–∞–¥—ã–≤–∞–µ–º ~{oos_len} –±–∞—Ä–æ–≤ –∫–∞–∫ –±—É–¥—É—â–µ–µ (OOS)."
            )
            # –í–ê–ñ–ù–û: –±–µ—Ä—ë–º –ò–ú–ï–ù–ù–û –Ω–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏ (–ø—Ä–æ—à–ª–æ–µ), –∞ –Ω–µ –∫–æ–Ω–µ—Ü
            balanced_frames = [df.iloc[:train_len].copy() for df in teacher_frames]
        else:
            print(f"   üîé –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º {min_len} –±–∞—Ä–∞–º (equal history).")
            balanced_frames = [df.iloc[-min_len:].copy() for df in teacher_frames]

        df_train_full = (
            pd.concat(balanced_frames, axis=0)
            .sample(frac=1.0, random_state=42)
        )

        print(f"üìä [UNIVERSAL] –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(df_train_full)} —Å—Ç—Ä–æ–∫.")
        print(f"   üß¨ –§–∏—á–∏ ({len(self.feature_cols)}): {self.feature_cols}")

        # 3.0) –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏—á–∏
        cols = [c for c in self.feature_cols if c in df_train_full.columns]
        missing = [c for c in self.feature_cols if c not in df_train_full.columns]

        if missing:
            print(f"   ‚ö†Ô∏è [UNIVERSAL] –ü—Ä–æ–ø—É—â–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ (–Ω–µ—Ç –≤ df): {missing}")

        if len(cols) < 3:
            print("   ‚ùå [UNIVERSAL] –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ñ–∏—á –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –æ–±—É—á–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
            return

        self.feature_cols = cols
        print(f"   ‚úÖ [UNIVERSAL] –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å {len(self.feature_cols)} —Ñ–∏—á: {self.feature_cols}")

        # 3.1) –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ø–∞–¥–∞–Ω–∏—è —Ü–µ–Ω –≤ —Ñ–∏—á–∏
        forbidden = {"close", "open", "high", "low"}
        for col in self.feature_cols:
            if col in forbidden:
                print(
                    f"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –í FEATURE_COLS –µ—Å—Ç—å —Ü–µ–Ω–æ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü '{col}'.\n"
                    f"    –£–±–µ—Ä–∏ –µ–≥–æ –∏–∑ Config.FEATURE_COLS –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏."
                )
                return

        # 4) –û–±—É—á–µ–Ω–∏–µ MLEngine –Ω–∞ –ú–ï–ì–ê-–¥–∞—Ç–∞—Å–µ—Ç–µ
        mode = Config.UNIVERSE_MODE
        model_name = f"UNIVERSAL_BRAIN_{mode.value}"
        model_path = os.path.join(Config.MODEL_DIR, model_name)
        os.makedirs(model_path, exist_ok=True)

        engine = MLEngine(model_path, regime_preset=self.preset)
        engine.train(df_train_full, self.feature_cols)

        print(f"‚úÖ [UNIVERSAL] –ì–ª–æ–±–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è {mode.value} –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_name}.")

        # -------- –ò–ù–§–ï–†–ï–ù–° –ù–ê –í–°–Å–ú –ü–û–†–¢–§–ï–õ–ï --------
        print("\nüîÆ [UNIVERSAL] –≠–∫–∑–∞–º–µ–Ω: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –ø–æ –≤—Å–µ–º—É –ø–æ—Ä—Ç—Ñ–µ–ª—é...")

        production_data: dict[str, pd.DataFrame] = {}

        for sym, df in self.data.items():
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ —Ä–µ–∂–∏–º–∞
            probs, regimes = engine.predict_batch(df, self.feature_cols)
            if probs is None:
                print(f"   ‚ö†Ô∏è {sym}: predict_batch –≤–µ—Ä–Ω—É–ª None, –ø—Ä–æ–ø—É—Å–∫.")
                continue

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ walk-forward
            df_res = pd.DataFrame(index=df.index)
            df_res["p_long"] = probs[:, 1]
            df_res["p_short"] = probs[:, 2]
            df_res["regime"] = regimes

            # –ö–æ–ø–∏—Ä—É–µ–º —Ü–µ–Ω—ã (–Ω—É–∂–Ω—ã –±—ç–∫—Ç–µ—Å—Ç–µ—Ä—É)
            for col in ["open", "high", "low", "close", "atr"]:
                if col in df.columns:
                    df_res[col] = df[col]

            production_data[sym] = df_res
            # –ú–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å –ª–æ–≥:
            # print(f"   ‚úÖ {sym}: —Å–∏–≥–Ω–∞–ª—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã ({len(df_res)} —Å—Ç—Ä–æ–∫).")

        # 5) –ú–µ—Ä–¥–∂–∏–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        merged_data = self._merge_with_existing_signals(production_data)

        with open(self.OUTPUT_FILE, "wb") as f:
            pickle.dump(merged_data, f)

        mode = Config.UNIVERSE_MODE
        print(f"üíæ [UNIVERSAL] –°–∏–≥–Ω–∞–ª—ã –¥–ª—è {mode.value} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã/–æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ {self.OUTPUT_FILE}")
        print("‚û°Ô∏è  –î–∞–ª—å—à–µ –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å debug_replayer.py / backtester.py")

    def _merge_with_existing_signals(self, new_signals: dict[str, pd.DataFrame]) -> dict[str, pd.DataFrame]:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç production_signals_v1.pkl —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–∫—É—â–µ–º—É —é–Ω–∏–≤–µ—Ä—Å—É.
        –û—Å—Ç–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤—ã (–¥—Ä—É–≥–∞—è –±–∏—Ä–∂–∞ / –¥—Ä—É–≥–∏–µ —Ä–µ–∂–∏–º—ã) –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.
        """
        result: dict[str, pd.DataFrame] = {}

        # 1) –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–∏–≥–Ω–∞–ª–æ–≤
        try:
            if os.path.exists(self.OUTPUT_FILE):
                with open(self.OUTPUT_FILE, "rb") as f:
                    old = pickle.load(f)
                if isinstance(old, dict):
                    result.update(old)
        except Exception as e:
            print(f"‚ö†Ô∏è [UNIVERSAL] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")

        # 2) –û–±–Ω–æ–≤–ª—è–µ–º / –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Ç–µ–∫—É—â–µ–≥–æ —é–Ω–∏–≤–µ—Ä—Å–∞
        for sym, df in new_signals.items():
            result[sym] = df

        return result

class SignalFactory:
    """
    –¶–µ—Ö –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (v2.0 - Incremental Edition).
    –£–º–Ω—ã–π Walk-Forward: –¥–æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é, –∞ –Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–∏—Ä —Å —Å–æ—Ç–≤–æ—Ä–µ–Ω–∏—è.
    """
    OUTPUT_FILE = "data_cache/production_signals_v1.pkl"

    def __init__(
        self,
        regime_preset: str = 'classic',
        force_reset: bool = False,
        train_window: int | None = None,
        trade_window: int | None = None,
    ):
        self.data = {}
        self.models = {}
        self.feature_cols = Config.FEATURE_COLS
        self.preset = regime_preset
        self.force_reset = force_reset
        # NEW: –æ–∫–Ω–∞ –∏–∑ GUI
        self.train_window = train_window
        self.trade_window = trade_window

    def load_data(self):
        mode = Config.UNIVERSE_MODE
        print(f"üèó [FACTORY] –ó–∞–≥—Ä—É–∑–∫–∞ —Å–≤–µ–∂–∏—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —é–Ω–∏–≤–µ—Ä—Å–∞: {mode.value}.")
        end = datetime.now()
        # –ì—Ä—É–∑–∏–º –∏—Å—Ç–æ—Ä–∏—é —Å –∑–∞–ø–∞—Å–æ–º, —á—Ç–æ–±—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ –ø–æ–ª–æ–º–∞–ª–∏—Å—å
        start = end - timedelta(days=2500) 
        
        leader_map = {sym: Config.get_leader_for_symbol(sym) for sym in Config.ASSETS}

        self.data = DataLoader.get_portfolio_data(
            Config.ASSETS,
            leader_map,
            start,
            end,
            Config.TIMEFRAME_LTF,
            Config.TIMEFRAME_HTF,
        )
        
        # Feature Engineering
        for sym, df in self.data.items():
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
            # print(f"   üõ† Features: {sym}") 
            df = FeatureEngineer.add_features(df)
            
            # Labeling —Å–æ–∑–¥–∞–µ—Ç 'target'. –ù—É–∂–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.
            # –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º Embargo –≤ run_walk_forward, —Ç–∞–∫ —á—Ç–æ —Ç—É—Ç –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑–º–µ—Ç–∫–∞.
            df = FeatureEngineer.label_data(df, Config.LOOK_AHEAD, Config.RR_RATIO)
            self.data[sym] = df
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–≤–∏–∂–∫–∏ (–ø—É—Å—Ç—ã–µ, –æ–Ω–∏ –±—É–¥—É—Ç –æ–±—É—á–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–∞)
            self.models[sym] = MLEngine(f"{Config.MODEL_DIR}/{sym}", regime_preset=self.preset)
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç–∏. –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: {len(self.data)}")

    def _load_existing_signals(self, master_index):
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ä—ã–π –∫—ç—à –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
           - production_data (—Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—É—é —Å—Ç–∞—Ä—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏)
           - start_idx (–æ—Ç–∫—É–¥–∞ –Ω–∞—á–∏–Ω–∞—Ç—å —Å—á–∏—Ç–∞—Ç—å –Ω–æ–≤—ã–µ)
        """
        if self.force_reset or not os.path.exists(self.OUTPUT_FILE):
            return None, None

        try:
            with open(self.OUTPUT_FILE, "rb") as f:
                old_data = pickle.load(f)

            if not old_data:
                return None, None

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏: –µ—Å—Ç—å –ª–∏ –≤—Å–µ –∞–∫—Ç–∏–≤—ã?
            first_sym = list(self.data.keys())[0]
            if first_sym not in old_data:
                print("‚ö†Ô∏è [CACHE] –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–∫—Ç–∏–≤–æ–≤ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å. –ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç.")
                return None, None

            # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –≤ –∫—ç—à–µ
            last_cache_date = old_data[first_sym].index[-1]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–∞ –¥–∞—Ç–∞ –≤ –Ω–æ–≤—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if last_cache_date not in master_index:
                print(f"‚ö†Ô∏è [CACHE] –ö—ç—à ({last_cache_date}) –Ω–µ —Å—Ç—ã–∫—É–µ—Ç—Å—è —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏. –ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç.")
                return None, None

            # –ò—â–µ–º integer index —ç—Ç–æ–π –¥–∞—Ç—ã –≤ –Ω–æ–≤–æ–º –º–∞—Å—Å–∏–≤–µ
            # get_loc –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å slice –∏–ª–∏ int, –±–µ—Ä–µ–º –∞–∫–∫—É—Ä–∞—Ç–Ω–æ
            idx_loc = master_index.get_loc(last_cache_date)
            if isinstance(idx_loc, slice):
                resume_idx = idx_loc.stop
            else:
                resume_idx = idx_loc + 1

            if resume_idx >= len(master_index):
                print("‚úÖ [CACHE] –ù–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç. –°–∏–≥–Ω–∞–ª—ã –∞–∫—Ç—É–∞–ª—å–Ω—ã.")
                return old_data, len(master_index) # Stop immediately

            print(f"‚ôªÔ∏è [CACHE] –ù–∞–π–¥–µ–Ω –∫—ç—à. –í–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å—á–µ—Ç —Å {master_index[resume_idx]} (skip {resume_idx} bars).")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: –±–µ—Ä–µ–º —Å—Ç–∞—Ä–æ–µ, —Ä–∞—Å—à–∏—Ä—è–µ–º –Ω–æ–≤—ã–º –ø—É—Å—Ç—ã–º –º–µ—Å—Ç–æ–º
            production_data = {}
            for sym in self.data:
                # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ñ—Ä–µ–π–º –ø–æ —Ä–∞–∑–º–µ—Ä—É –ù–û–í–´–• –¥–∞–Ω–Ω—ã—Ö
                full_index = self.data[sym].index
                df_res = pd.DataFrame(index=full_index)
                df_res['p_long'] = 0.0
                df_res['p_short'] = 0.0
                df_res['regime'] = 0
                
                # –ö–æ–ø–∏—Ä—É–µ–º —Ü–µ–Ω—ã (–æ–Ω–∏ –≤—Å–µ–≥–¥–∞ —Å–≤–µ–∂–∏–µ –∏–∑ load_data)
                src = self.data[sym]
                for col in ['open', 'high', 'low', 'close', 'atr']:
                    if col in src.columns:
                        df_res[col] = src[col]

                # –í—Å—Ç–∞–≤–ª—è–µ–º –°–¢–ê–†–´–ï –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –Ω–∞—á–∞–ª–æ
                if sym in old_data:
                    old_df = old_data[sym]
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º update –∏–ª–∏ –ø—Ä—è–º–æ–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ –ø–æ –∏–Ω–¥–µ–∫—Å—É
                    # –í–∞–∂–Ω–æ: –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ intersection –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–∞ —Å–ª—É—á–∞–π –¥—ã—Ä
                    common_idx = old_df.index.intersection(full_index)
                    
                    df_res.loc[common_idx, 'p_long'] = old_df.loc[common_idx, 'p_long']
                    df_res.loc[common_idx, 'p_short'] = old_df.loc[common_idx, 'p_short']
                    df_res.loc[common_idx, 'regime'] = old_df.loc[common_idx, 'regime']
                
                production_data[sym] = df_res
            
            return production_data, resume_idx

        except Exception as e:
            print(f"‚ùå [CACHE ERROR] {e}. –ù–∞—á–∏–Ω–∞–µ–º —Å –Ω—É–ª—è.")
            return None, None

    def run_walk_forward(self):
        """
        –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è.
        """
        if not self.data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ load_data().")
            return

        master_sym = list(self.data.keys())[0]
        master_index = self.data[master_sym].index
        total_steps = len(master_index)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫–Ω–∞
        window_size = self.train_window or Config.WALK_FORWARD_WINDOW  # –û–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è
        if self.trade_window is not None and self.trade_window > 0:
            step_size = int(self.trade_window)
            if step_size > window_size:
                step_size = window_size
        else:
            step_size = int(window_size * 0.25)  # –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
        
        step_size = max(1, step_size)
        
        # --- 1. –ü–û–ü–´–¢–ö–ê –ó–ê–ì–†–£–ó–ö–ò –ö–≠–®–ê ---
        production_data, start_idx = self._load_existing_signals(master_index)
        
        if production_data is None:
            # –ï—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å –Ω—É–ª—è
            start_idx = window_size + Config.LOOK_AHEAD
            production_data = {}
            for sym in self.data:
                idx = self.data[sym].index
                df_res = pd.DataFrame(index=idx)
                df_res['p_long'] = 0.0; df_res['p_short'] = 0.0; df_res['regime'] = 0
                
                src = self.data[sym]
                for col in ['open', 'high', 'low', 'close', 'atr']:
                    if col in src.columns: df_res[col] = src[col]
                production_data[sym] = df_res

        # –ï—Å–ª–∏ —É–∂–µ –≤—Å–µ –ø–æ—Å—á–∏—Ç–∞–Ω–æ
        if start_idx >= total_steps:
            return

        print(f"üöÄ [FACTORY] –°—Ç–∞—Ä—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {total_steps - start_idx} –Ω–æ–≤—ã—Ö –±–∞—Ä–æ–≤...")
        
        current_idx = start_idx
        pbar = tqdm(total=total_steps - start_idx)
        
        # --- 2. –¶–ò–ö–õ (–¢–æ–ª—å–∫–æ –ø–æ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º) ---
        while current_idx < total_steps:
            # A. TRAIN PHASE
            train_start = max(0, current_idx - window_size - Config.LOOK_AHEAD)
            train_end = current_idx - Config.LOOK_AHEAD 
            
            if train_end > train_start + 500:
                # Parallel Training
                n_cores = max(1, multiprocessing.cpu_count() - 1)
                
                # We pass the EXTERNAL function train_wrapper here
                results = Parallel(n_jobs=n_cores, backend="loky")(
                    delayed(train_wrapper)(
                        sym, 
                        self.models[sym], 
                        self.data[sym].iloc[train_start:train_end], 
                        self.feature_cols
                    ) for sym in self.data
                )

                # Collect results back to main process
                for sym, trained_model in results:
                    self.models[sym] = trained_model
            
            # B. PREDICT PHASE
            test_end = min(total_steps, current_idx + step_size)
            
            for sym in self.data:
                df_full = self.data[sym]
                df_test_chunk = df_full.iloc[current_idx:test_end]
                
                if df_test_chunk.empty: continue
                
                # –í–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–µ–¥–∏–∫—Ç
                probs, regimes = self.models[sym].predict_batch(df_test_chunk, self.feature_cols)
                
                if probs is not None:
                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ production_data
                    # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º .iloc –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏, —Ç–∞–∫ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    # –ù–æ production_data[sym] —ç—Ç–æ –ø–æ–ª–Ω—ã–π —Ñ—Ä–µ–π–º.
                    # –ü—Ä–æ—â–µ —á–µ—Ä–µ–∑ .loc –ø–æ –∏–Ω–¥–µ–∫—Å—É —á–∞–Ω–∫–∞
                    target_idx = df_test_chunk.index
                    
                    production_data[sym].loc[target_idx, 'p_long'] = probs[:, 1]
                    production_data[sym].loc[target_idx, 'p_short'] = probs[:, 2]
                    production_data[sym].loc[target_idx, 'regime'] = regimes

            processed_count = test_end - current_idx
            pbar.update(processed_count)
            current_idx = test_end
            
            # C. INTERMEDIATE SAVE (–ö–∞–∂–¥—ã–µ 5 —à–∞–≥–æ–≤ —Ü–∏–∫–ª–∞ –∏–ª–∏ –≤ –∫–æ–Ω—Ü–µ)
            # –ß—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –ø—Ä–∏ –∫—Ä–∞—à–µ
            # (–î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ–Ω—Ü–µ, –Ω–æ –º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –ø–∞—Ä–∞–Ω–æ–∏–¥–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞)
            # if current_idx % (step_size * 5) == 0:
            #     self._save_to_disk(production_data)

        pbar.close()
        
        # --- 3. –§–ò–ù–ê–õ–¨–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï ---
        self._save_to_disk(production_data)

    def _save_to_disk(self, production_data):
        # –û–±—Ä–µ–∑–∫–∞ "—Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞" (–≥–¥–µ –Ω—É–ª–∏ –≤ –Ω–∞—á–∞–ª–µ —Å–∞–º–æ–º-—Å–∞–º–æ–º)
        # –ï—Å–ª–∏ –º—ã –¥–æ–ø–∏—Å—ã–≤–∞–ª–∏ –∫—ç—à, —Ç–æ –Ω–∞—á–∞–ª–æ —É–∂–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ.
        # –ù–∞–π–¥–µ–º –ø–µ—Ä–≤—É—é –¥–∞—Ç—É, –≥–¥–µ p_long != 0
        
        final_output = {}
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –∏—â–µ–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å —Å –Ω–µ–Ω—É–ª–µ–≤–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é —É –ª–∏–¥–µ—Ä–∞
        master_sym = list(production_data.keys())[0]
        df_master = production_data[master_sym]
        
        # –ë–µ—Ä–µ–º –∏–Ω–¥–µ–∫—Å, –≥–¥–µ –≤–ø–µ—Ä–≤—ã–µ –ø–æ—è–≤–∏–ª–∏—Å—å –¥–∞–Ω–Ω—ã–µ (–∏–ª–∏ –Ω–∞—á–∞–ª–æ –∫—ç—à–∞, –∏–ª–∏ –Ω–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞)
        # –ù–æ —á—Ç–æ–±—ã –Ω–µ —É—Å–ª–æ–∂–Ω—è—Ç—å, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å—ë, –∫—Ä–æ–º–µ –æ—Ç–∫—Ä–æ–≤–µ–Ω–Ω–æ–π –ø—É—Å—Ç–æ—Ç—ã –≤ –Ω–∞—á–∞–ª–µ –∏—Å—Ç–æ—Ä–∏–∏
        
        valid_idx = df_master[(df_master['p_long'] != 0) | (df_master['p_short'] != 0)].index
        if not valid_idx.empty:
            start_date = valid_idx[0]
        else:
            start_date = df_master.index[0]

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ (c {start_date})...")
        
        for sym, df in production_data.items():
            final_output[sym] = df.loc[start_date:]
            
        with open(self.OUTPUT_FILE, "wb") as f:
            pickle.dump(final_output, f)
            
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {self.OUTPUT_FILE}")

    def _merge_with_existing_signals(self, new_signals: dict[str, pd.DataFrame]) -> dict[str, pd.DataFrame]:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç production_signals_v1.pkl —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–∫—É—â–µ–º—É —é–Ω–∏–≤–µ—Ä—Å—É.
        –û—Å—Ç–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤—ã (–¥—Ä—É–≥–∞—è –±–∏—Ä–∂–∞) –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.
        """
        result: dict[str, pd.DataFrame] = {}

        # 1) –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª
        try:
            if os.path.exists(self.OUTPUT_FILE):
                with open(self.OUTPUT_FILE, "rb") as f:
                    old = pickle.load(f)
                if isinstance(old, dict):
                    result.update(old)
        except Exception as e:
            print(f"‚ö†Ô∏è [UNIVERSAL] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")

        # 2) –û–±–Ω–æ–≤–ª—è–µ–º / –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Ç–µ–∫—É—â–µ–≥–æ —é–Ω–∏–≤–µ—Ä—Å–∞
        for sym, df in new_signals.items():
            result[sym] = df

        return result

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Signal Factory & ML Trainer")
    parser.add_argument(
        "--preset",
        type=str,
        default="classic",
        choices=["classic", "grinder", "sniper", "loose"],
        help="Market regime preset",
    )
    parser.add_argument(
        "--reset",
        action="store_true",
        help="Force delete cache and recalculate everything (walk mode only)",
    )
    parser.add_argument(
        "--mode",
        type=str,
        default="walk",
        choices=["walk", "universal"],
        help="Signal generation mode: walk (per-symbol WF) or universal (global brain)",
    )
    # NEW: –æ–∫–Ω–∞ WF –∏–∑ GUI
    parser.add_argument(
        "--train_window",
        type=int,
        default=None,
        help="Train window in candles (WF & Universal CA-WF)",
    )
    parser.add_argument(
        "--trade_window",
        type=int,
        default=None,
        help="Trade/OOS window in candles",
    )
    # NEW: —Ñ–ª–∞–≥ –≤–∫–ª—é—á–µ–Ω–∏—è Cross-Asset WF
    parser.add_argument(
        "--cross_asset_wf",
        action="store_true",
        help="Enable Cross-Asset Walk-Forward for UNIVERSAL mode",
    )

    args = parser.parse_args()

    if args.mode == "walk":
        print(f"\nüè≠ [FACTORY] –ó–∞–ø—É—Å–∫ WALK-FORWARD. Preset: {args.preset.upper()}")
        if args.reset:
            print("‚ö†Ô∏è FORCE RESET: –∫—ç—à —Å–∏–≥–Ω–∞–ª–æ–≤ –±—É–¥–µ—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω.")

        factory = SignalFactory(
            regime_preset=args.preset,
            force_reset=args.reset,
            train_window=args.train_window,
            trade_window=args.trade_window,
        )
        factory.load_data()
        factory.run_walk_forward()
        print("\n‚û°Ô∏è –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: python optimizer.py --mode sniper")

    else:
        print(f"\nüß† [UNIVERSAL] –ó–∞–ø—É—Å–∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –º–æ–∑–≥–∞. Preset: {args.preset.upper()}")
        u_factory = UniversalSignalFactory(
            regime_preset=args.preset,
            cross_asset_wf=args.cross_asset_wf,
            train_window=args.train_window,
            trade_window=args.trade_window,
        )
        u_factory.load_data()
        u_factory.run_universal_training()
        # –î–∞–ª—å—à–µ –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –≥–æ–Ω—è—Ç—å backtester –ø–æ production_signals_v1.pkl