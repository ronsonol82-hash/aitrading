# signal_generator.py
import pandas as pd
import numpy as np
import pickle
import os
import sys
import asyncio
from tqdm import tqdm
from datetime import datetime, timedelta
from config import Config, UniverseMode
from data_loader import DataLoader
from indicators import FeatureEngineer
from model_engine import MLEngine
from risk_utils import calc_position_size
import argparse
from joblib import Parallel, delayed
import multiprocessing

# --- HELPER FOR PARALLEL TRAINING ---
def train_wrapper(sym, model_obj, data_slice, features):
    # This runs in a separate process
    try:
        model_obj.train(data_slice, features)
        return sym, model_obj
    except Exception as e:
        print(f"‚ùå Error training {sym}: {e}")
        return sym, model_obj # Return old model if failed

class UniversalSignalFactory:
    """
    –§–∞–±—Ä–∏–∫–∞ –°–∏–≥–Ω–∞–ª–æ–≤ v3.0 (Universal Brain Edition).

    –û–±—É—á–∞–µ—Ç –ï–î–ò–ù–£–Æ –º–æ–¥–µ–ª—å –Ω–∞ –æ–±—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω–µ:
      - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ—Ö —É—á–∏—Ç–µ–ª–µ–π –∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è,
      - –ø—Ä–∏–º–µ–Ω—è–µ–º –µ—ë –∫–æ –≤—Å–µ–º—É —Å–ø–∏—Å–∫—É Config.ASSETS.
    """
    OUTPUT_FILE = "data_cache/production_signals_v1.pkl"

    def __init__(
        self,
        regime_preset: str = "classic",
        cross_asset_wf: bool = False,
        train_window: int | None = None,
        trade_window: int | None = None,
        ):
        self.preset = regime_preset
        self.cross_asset_wf = cross_asset_wf
        self.train_window = train_window
        self.trade_window = trade_window

        self.data: dict[str, pd.DataFrame] = {}

        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä —Ñ–∏—á –±–µ–∑ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö —Ü–µ–Ω
        # (align —Å Config.UNIVERSAL_FEATURE_COLS)
        self.feature_cols = Config.UNIVERSAL_FEATURE_COLS

        # üß† –£—á–∏—Ç–µ–ª—è –∑–∞–≤—è–∑—ã–≤–∞–µ–º –Ω–∞ UNIVERSE_MODE + cross_asset_wf
        mode = Config.UNIVERSE_MODE

        if self.cross_asset_wf:
            # –ö—Ä–æ—Å—Å-–∞–∫—Ç–∏–≤–Ω—ã–π WF –≤–Ω—É—Ç—Ä–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –≤—Å–µ–ª–µ–Ω–Ω–æ–π
            if mode == UniverseMode.CRYPTO:
                # —Ç–æ–ª—å–∫–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã
                self.teachers = Config.crypto_symbols()
            elif mode == UniverseMode.STOCKS:
                # —Ç–æ–ª—å–∫–æ –∞–∫—Ü–∏–∏/–≤–∞–ª—é—Ç—ã –±–∏—Ä–∂–∏
                self.teachers = Config.equity_symbols()
            else:
                # BOTH: –±–µ—Ä—ë–º –≤—Å–µ –∫–ª–∞—Å—Å—ã
                self.teachers = Config.crypto_symbols() + Config.equity_symbols()
        else:
            # –ë–µ–∑ cross-asset: —É—á–∏—Ç–µ–ª—è = —Ç–µ–∫—É—â–∏–π —Ç–æ—Ä–≥–æ–≤—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å
            # (—Ç–æ, —á—Ç–æ –≤—ã–±—Ä–∞–Ω–æ —á–µ—Ä–µ–∑ UNIVERSE_MODE / GUI)
            self.teachers = ["MOEX"]

        # –ï—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å —Å—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ, –º–æ–∂–Ω–æ –≤—Ä—É—á–Ω—É—é –∑–∞–¥–∞—Ç—å –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ:
        # self.teachers = ["MOEX"] //// self.teachers = Config.ASSETS
            
    # -------- –ó–ê–ì–†–£–ó–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• --------
    def load_data(self) -> None:
        print("üèó [UNIVERSAL FACTORY] –ó–∞–≥—Ä—É–∑–∫–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
        end = datetime.now()
        # –ì–ª—É–±–æ–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (‚âà 6‚Äì7 –ª–µ—Ç)
        start = end - timedelta(days=2500)

        mode = Config.UNIVERSE_MODE
        if mode == UniverseMode.CRYPTO:
            # –¢–æ–ª—å–∫–æ –∫—Ä–∏–ø—Ç–∞
            all_assets = Config.crypto_symbols()
        elif mode == UniverseMode.STOCKS:
            # –¢–æ–ª—å–∫–æ –±–∏—Ä–∂–∞ (MOEX / –¢–∏–Ω—å–∫–æ—Ñ—Ñ)
            all_assets = Config.equity_symbols()
        else:
            # BOTH ‚Äî –æ–±—ä–µ–¥–∏–Ω—è–µ–º –¥–≤–∞ —Å–ø–∏—Å–∫–∞
            all_assets = Config.crypto_symbols() + Config.equity_symbols()

        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —É–±–µ—Ä—ë–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        all_assets = list(sorted(set(all_assets)))
        print(f"   üì• –ó–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ({mode.value}): {all_assets}")

        leader_map = {sym: Config.get_leader_for_symbol(sym) for sym in all_assets}

        self.data = DataLoader.get_portfolio_data(
            all_assets,
            leader_map,
            start,
            end,
            Config.TIMEFRAME_LTF,
            Config.TIMEFRAME_HTF,
        )

        if not self.data:
            print("‚ùå [UNIVERSAL] –û—à–∏–±–∫–∞: DataLoader –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å.")
            sys.exit(1)

        print("üõ† –†–∞—Å—á—ë—Ç —Ñ–∏—á–µ–π (price-agnostic —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ + –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è —É—Ä–æ–≤–Ω–µ–π)...")
        for sym, df in tqdm(self.data.items(), desc="Feature Engineering"):
            try:
                # 1) –§–∏—á–∏ (—É—Ä–æ–≤–Ω–∏, –∫–∞–Ω–∞–ª, –∫–æ–Ωfluence score –∏ —Ç.–¥.)
                df_feat = FeatureEngineer.add_features(df)

                # 2) –†–∞–∑–º–µ—Ç–∫–∞ triple-barrier (target)
                df_labeled = FeatureEngineer.label_data(
                    df_feat, Config.LOOK_AHEAD, Config.RR_RATIO
                )

                # Drop NaN –∏–∑-–∑–∞ —Ä–æ–ª–ª–∏–Ω–≥–æ–≤/ATR
                self.data[sym] = df_labeled.dropna()
            except Exception as e:
                print(f"‚ö†Ô∏è [UNIVERSAL] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {sym}: {e}")

        print(f"‚úÖ [UNIVERSAL] –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã. –ê–∫—Ç–∏–≤–æ–≤ –≤ –ø–∞–º—è—Ç–∏: {len(self.data)}")

    # -------- –û–ë–£–ß–ï–ù–ò–ï –ì–õ–û–ë–ê–õ–¨–ù–û–ì–û –ú–û–ó–ì–ê --------
    def run_universal_training(self) -> None:
        if not self.data:
            print("‚ùå [UNIVERSAL] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏ load_data().")
            return

        print("\nüéì [UNIVERSAL] –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –ì–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ú–æ–∑–≥–∞...")
        print(f"   üë®‚Äçüè´ –£—á–∏—Ç–µ–ª—è: {self.teachers}")
        if self.cross_asset_wf:
            print("   üåâ –†–µ–∂–∏–º: CROSS-ASSET WALK-FORWARD –≤–∫–ª—é—á–µ–Ω.")
            if self.train_window or self.trade_window:
                print(
                    f"   üìê –û–∫–Ω–∞: train_window={self.train_window}, "
                    f"trade_window={self.trade_window}"
                )
        teacher_frames: list[pd.DataFrame] = []
        min_len = float("inf")

        # 1) –°–æ–±–∏—Ä–∞–µ–º —É—á–∏—Ç–µ–ª–µ–π –∏ –Ω–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏
        for sym in self.teachers:
            if sym not in self.data:
                print(f"   ‚ö†Ô∏è –£—á–∏—Ç–µ–ª—å {sym} –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue

            df = self.data[sym]
            if len(df) < 100:
                print(f"   ‚ö†Ô∏è {sym}: —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –±–∞—Ä–æ–≤ ({len(df)}), –ø—Ä–æ–ø—É—Å–∫.")
                continue

            teacher_frames.append(df)
            if len(df) < min_len:
                min_len = len(df)

            print(f"   ‚úîÔ∏è {sym}: {len(df)} –±–∞—Ä–æ–≤ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.")

        if not teacher_frames:
            print("‚ùå [UNIVERSAL] –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —É—á–∏—Ç–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
            return

        lengths = [len(x) for x in teacher_frames]
        print(f"   üìè –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —É—á–∏—Ç–µ–ª—å—Å–∫–∏—Ö –≤—ã–±–æ—Ä–æ–∫: {lengths}")
        
        if self.cross_asset_wf:
            total_bars = min_len

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏–Ω—É train / OOS
            if self.train_window is not None and self.trade_window is not None:
                train_len = min(self.train_window, total_bars - 50)
                oos_len = min(self.trade_window, total_bars - train_len)
            elif self.train_window is not None:
                train_len = min(self.train_window, total_bars - 50)
                oos_len = total_bars - train_len
            elif self.trade_window is not None:
                oos_len = min(self.trade_window, max(50, total_bars // 3))
                train_len = total_bars - oos_len
            else:
                train_len = int(total_bars * 0.7)
                oos_len = total_bars - train_len

            if train_len <= 0:
                print("‚ùå [UNIVERSAL-CA] –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –æ–∫–Ω–∞ train/test. "
                      "–£–º–µ–Ω—å—à–∏ trade_window –∏–ª–∏ —É–≤–µ–ª–∏—á—å train_window.")
                return

            print(
                f"   üß™ [CA-WF] –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ {train_len} –±–∞—Ä–æ–≤ —É—á–∏—Ç–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è "
                f"–∏ –æ—Ç–∫–ª–∞–¥—ã–≤–∞–µ–º ~{oos_len} –±–∞—Ä–æ–≤ –∫–∞–∫ –±—É–¥—É—â–µ–µ (OOS)."
            )
            # –í–ê–ñ–ù–û: –±–µ—Ä—ë–º –ò–ú–ï–ù–ù–û –Ω–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏ (–ø—Ä–æ—à–ª–æ–µ), –∞ –Ω–µ –∫–æ–Ω–µ—Ü
            balanced_frames = [df.iloc[:train_len].copy() for df in teacher_frames]
        else:
            print(f"   üîé –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º {min_len} –±–∞—Ä–∞–º (equal history).")
            balanced_frames = [df.iloc[-min_len:].copy() for df in teacher_frames]

        df_train_full = (
            pd.concat(balanced_frames, axis=0)
            .sample(frac=1.0, random_state=42)
        )

        print(f"üìä [UNIVERSAL] –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(df_train_full)} —Å—Ç—Ä–æ–∫.")
        print(f"   üß¨ –§–∏—á–∏ ({len(self.feature_cols)}): {self.feature_cols}")

        # 3.0) –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏—á–∏
        cols = [c for c in self.feature_cols if c in df_train_full.columns]
        missing = [c for c in self.feature_cols if c not in df_train_full.columns]

        if missing:
            print(f"   ‚ö†Ô∏è [UNIVERSAL] –ü—Ä–æ–ø—É—â–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ (–Ω–µ—Ç –≤ df): {missing}")

        if len(cols) < 3:
            print("   ‚ùå [UNIVERSAL] –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ñ–∏—á –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –æ–±—É—á–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
            return

        self.feature_cols = cols
        print(f"   ‚úÖ [UNIVERSAL] –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å {len(self.feature_cols)} —Ñ–∏—á: {self.feature_cols}")

        # 3.1) –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ø–∞–¥–∞–Ω–∏—è —Ü–µ–Ω –≤ —Ñ–∏—á–∏
        forbidden = {"close", "open", "high", "low"}
        for col in self.feature_cols:
            if col in forbidden:
                print(
                    f"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –í FEATURE_COLS –µ—Å—Ç—å —Ü–µ–Ω–æ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü '{col}'.\n"
                    f"    –£–±–µ—Ä–∏ –µ–≥–æ –∏–∑ Config.FEATURE_COLS –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏."
                )
                return

        # 4) –û–±—É—á–µ–Ω–∏–µ MLEngine –Ω–∞ –ú–ï–ì–ê-–¥–∞—Ç–∞—Å–µ—Ç–µ
        mode = Config.UNIVERSE_MODE
        model_name = f"UNIVERSAL_BRAIN_{mode.value}"
        model_path = os.path.join(Config.MODEL_DIR, model_name)
        os.makedirs(model_path, exist_ok=True)

        engine = MLEngine(model_path, regime_preset=self.preset)
        engine.train(df_train_full, self.feature_cols)

        print(f"‚úÖ [UNIVERSAL] –ì–ª–æ–±–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è {mode.value} –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_name}.")

        # -------- –ò–ù–§–ï–†–ï–ù–° –ù–ê –í–°–Å–ú –ü–û–†–¢–§–ï–õ–ï --------
        print("\nüîÆ [UNIVERSAL] –≠–∫–∑–∞–º–µ–Ω: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –ø–æ –≤—Å–µ–º—É –ø–æ—Ä—Ç—Ñ–µ–ª—é...")

        production_data: dict[str, pd.DataFrame] = {}

        for sym, df in self.data.items():
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ —Ä–µ–∂–∏–º–∞
            probs, regimes = engine.predict_batch(df, self.feature_cols)
            if probs is None:
                print(f"   ‚ö†Ô∏è {sym}: predict_batch –≤–µ—Ä–Ω—É–ª None, –ø—Ä–æ–ø—É—Å–∫.")
                continue

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ walk-forward
            df_res = pd.DataFrame(index=df.index)
            df_res["p_long"] = probs[:, 1]
            df_res["p_short"] = probs[:, 2]
            df_res["regime"] = regimes

            # –ö–æ–ø–∏—Ä—É–µ–º —Ü–µ–Ω—ã (–Ω—É–∂–Ω—ã –±—ç–∫—Ç–µ—Å—Ç–µ—Ä—É)
            for col in ["open", "high", "low", "close", "atr"]:
                if col in df.columns:
                    df_res[col] = df[col]

            production_data[sym] = df_res
            # –ú–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å –ª–æ–≥:
            # print(f"   ‚úÖ {sym}: —Å–∏–≥–Ω–∞–ª—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã ({len(df_res)} —Å—Ç—Ä–æ–∫).")

        # 5) –ú–µ—Ä–¥–∂–∏–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        merged_data = self._merge_with_existing_signals(production_data)

        with open(self.OUTPUT_FILE, "wb") as f:
            pickle.dump(merged_data, f)

        mode = Config.UNIVERSE_MODE
        print(f"üíæ [UNIVERSAL] –°–∏–≥–Ω–∞–ª—ã –¥–ª—è {mode.value} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã/–æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ {self.OUTPUT_FILE}")
        print("‚û°Ô∏è  –î–∞–ª—å—à–µ –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å debug_replayer.py / backtester.py")

    def _merge_with_existing_signals(self, new_signals: dict[str, pd.DataFrame]) -> dict[str, pd.DataFrame]:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç production_signals_v1.pkl —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–∫—É—â–µ–º—É —é–Ω–∏–≤–µ—Ä—Å—É.
        –û—Å—Ç–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤—ã (–¥—Ä—É–≥–∞—è –±–∏—Ä–∂–∞ / –¥—Ä—É–≥–∏–µ —Ä–µ–∂–∏–º—ã) –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.
        """
        result: dict[str, pd.DataFrame] = {}

        # 1) –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–∏–≥–Ω–∞–ª–æ–≤
        try:
            if os.path.exists(self.OUTPUT_FILE):
                with open(self.OUTPUT_FILE, "rb") as f:
                    old = pickle.load(f)
                if isinstance(old, dict):
                    result.update(old)
        except Exception as e:
            print(f"‚ö†Ô∏è [UNIVERSAL] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")

        # 2) –û–±–Ω–æ–≤–ª—è–µ–º / –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Ç–µ–∫—É—â–µ–≥–æ —é–Ω–∏–≤–µ—Ä—Å–∞
        for sym, df in new_signals.items():
            result[sym] = df

        return result

class SignalFactory:
    """
    –¶–µ—Ö –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (v2.0 - Incremental Edition).
    –£–º–Ω—ã–π Walk-Forward: –¥–æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é, –∞ –Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–∏—Ä —Å —Å–æ—Ç–≤–æ—Ä–µ–Ω–∏—è.
    """
    OUTPUT_FILE = "data_cache/production_signals_v1.pkl"

    def __init__(
        self,
        regime_preset: str = 'classic',
        force_reset: bool = False,
        train_window: int | None = None,
        trade_window: int | None = None,
    ):
        self.data = {}
        self.models = {}
        self.feature_cols = Config.FEATURE_COLS
        self.preset = regime_preset
        self.force_reset = force_reset
        # NEW: –æ–∫–Ω–∞ –∏–∑ GUI
        self.train_window = train_window
        self.trade_window = trade_window

    def load_data(self):
        mode = Config.UNIVERSE_MODE
        print(f"üèó [FACTORY] –ó–∞–≥—Ä—É–∑–∫–∞ —Å–≤–µ–∂–∏—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —é–Ω–∏–≤–µ—Ä—Å–∞: {mode.value}.")
        end = datetime.now()
        # –ì—Ä—É–∑–∏–º –∏—Å—Ç–æ—Ä–∏—é —Å –∑–∞–ø–∞—Å–æ–º, —á—Ç–æ–±—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ –ø–æ–ª–æ–º–∞–ª–∏—Å—å
        start = end - timedelta(days=2500) 
        
        leader_map = {sym: Config.get_leader_for_symbol(sym) for sym in Config.ASSETS}

        self.data = DataLoader.get_portfolio_data(
            Config.ASSETS,
            leader_map,
            start,
            end,
            Config.TIMEFRAME_LTF,
            Config.TIMEFRAME_HTF,
        )
        
        # Feature Engineering
        for sym, df in self.data.items():
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
            # print(f"   üõ† Features: {sym}") 
            df = FeatureEngineer.add_features(df)
            
            # Labeling —Å–æ–∑–¥–∞–µ—Ç 'target'. –ù—É–∂–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.
            # –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º Embargo –≤ run_walk_forward, —Ç–∞–∫ —á—Ç–æ —Ç—É—Ç –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑–º–µ—Ç–∫–∞.
            df = FeatureEngineer.label_data(df, Config.LOOK_AHEAD, Config.RR_RATIO)
            self.data[sym] = df
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–≤–∏–∂–∫–∏ (–ø—É—Å—Ç—ã–µ, –æ–Ω–∏ –±—É–¥—É—Ç –æ–±—É—á–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–∞)
            self.models[sym] = MLEngine(f"{Config.MODEL_DIR}/{sym}", regime_preset=self.preset)
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç–∏. –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: {len(self.data)}")

    def _load_existing_signals(self, master_index):
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ä—ã–π –∫—ç—à –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
           - production_data (—Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—É—é —Å—Ç–∞—Ä—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏)
           - start_idx (–æ—Ç–∫—É–¥–∞ –Ω–∞—á–∏–Ω–∞—Ç—å —Å—á–∏—Ç–∞—Ç—å –Ω–æ–≤—ã–µ)
        """
        if self.force_reset or not os.path.exists(self.OUTPUT_FILE):
            return None, None

        try:
            with open(self.OUTPUT_FILE, "rb") as f:
                old_data = pickle.load(f)

            if not old_data:
                return None, None

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏: –µ—Å—Ç—å –ª–∏ –≤—Å–µ –∞–∫—Ç–∏–≤—ã?
            first_sym = list(self.data.keys())[0]
            if first_sym not in old_data:
                print("‚ö†Ô∏è [CACHE] –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–∫—Ç–∏–≤–æ–≤ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å. –ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç.")
                return None, None

            # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –≤ –∫—ç—à–µ
            last_cache_date = old_data[first_sym].index[-1]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–∞ –¥–∞—Ç–∞ –≤ –Ω–æ–≤—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if last_cache_date not in master_index:
                print(f"‚ö†Ô∏è [CACHE] –ö—ç—à ({last_cache_date}) –Ω–µ —Å—Ç—ã–∫—É–µ—Ç—Å—è —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏. –ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç.")
                return None, None

            # –ò—â–µ–º integer index —ç—Ç–æ–π –¥–∞—Ç—ã –≤ –Ω–æ–≤–æ–º –º–∞—Å—Å–∏–≤–µ
            # get_loc –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å slice –∏–ª–∏ int, –±–µ—Ä–µ–º –∞–∫–∫—É—Ä–∞—Ç–Ω–æ
            idx_loc = master_index.get_loc(last_cache_date)
            if isinstance(idx_loc, slice):
                resume_idx = idx_loc.stop
            else:
                resume_idx = idx_loc + 1

            if resume_idx >= len(master_index):
                print("‚úÖ [CACHE] –ù–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç. –°–∏–≥–Ω–∞–ª—ã –∞–∫—Ç—É–∞–ª—å–Ω—ã.")
                return old_data, len(master_index) # Stop immediately

            print(f"‚ôªÔ∏è [CACHE] –ù–∞–π–¥–µ–Ω –∫—ç—à. –í–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å—á–µ—Ç —Å {master_index[resume_idx]} (skip {resume_idx} bars).")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: –±–µ—Ä–µ–º —Å—Ç–∞—Ä–æ–µ, —Ä–∞—Å—à–∏—Ä—è–µ–º –Ω–æ–≤—ã–º –ø—É—Å—Ç—ã–º –º–µ—Å—Ç–æ–º
            production_data = {}
            for sym in self.data:
                # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ñ—Ä–µ–π–º –ø–æ —Ä–∞–∑–º–µ—Ä—É –ù–û–í–´–• –¥–∞–Ω–Ω—ã—Ö
                full_index = self.data[sym].index
                df_res = pd.DataFrame(index=full_index)
                df_res['p_long'] = 0.0
                df_res['p_short'] = 0.0
                df_res['regime'] = 0
                
                # –ö–æ–ø–∏—Ä—É–µ–º —Ü–µ–Ω—ã (–æ–Ω–∏ –≤—Å–µ–≥–¥–∞ —Å–≤–µ–∂–∏–µ –∏–∑ load_data)
                src = self.data[sym]
                for col in ['open', 'high', 'low', 'close', 'atr']:
                    if col in src.columns:
                        df_res[col] = src[col]

                # –í—Å—Ç–∞–≤–ª—è–µ–º –°–¢–ê–†–´–ï –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –Ω–∞—á–∞–ª–æ
                if sym in old_data:
                    old_df = old_data[sym]
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º update –∏–ª–∏ –ø—Ä—è–º–æ–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ –ø–æ –∏–Ω–¥–µ–∫—Å—É
                    # –í–∞–∂–Ω–æ: –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ intersection –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–∞ —Å–ª—É—á–∞–π –¥—ã—Ä
                    common_idx = old_df.index.intersection(full_index)
                    
                    df_res.loc[common_idx, 'p_long'] = old_df.loc[common_idx, 'p_long']
                    df_res.loc[common_idx, 'p_short'] = old_df.loc[common_idx, 'p_short']
                    df_res.loc[common_idx, 'regime'] = old_df.loc[common_idx, 'regime']
                
                production_data[sym] = df_res
            
            return production_data, resume_idx

        except Exception as e:
            print(f"‚ùå [CACHE ERROR] {e}. –ù–∞—á–∏–Ω–∞–µ–º —Å –Ω—É–ª—è.")
            return None, None

    def run_walk_forward(self):
        """
        –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è.
        """
        if not self.data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ load_data().")
            return

        master_sym = list(self.data.keys())[0]
        master_index = self.data[master_sym].index
        total_steps = len(master_index)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫–Ω–∞
        window_size = self.train_window or Config.WALK_FORWARD_WINDOW  # –û–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è
        if self.trade_window is not None and self.trade_window > 0:
            step_size = int(self.trade_window)
            if step_size > window_size:
                step_size = window_size
        else:
            step_size = int(window_size * 0.25)  # –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
        
        step_size = max(1, step_size)
        
        # --- 1. –ü–û–ü–´–¢–ö–ê –ó–ê–ì–†–£–ó–ö–ò –ö–≠–®–ê ---
        production_data, start_idx = self._load_existing_signals(master_index)
        
        if production_data is None:
            # –ï—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å –Ω—É–ª—è
            start_idx = window_size + Config.LOOK_AHEAD
            production_data = {}
            for sym in self.data:
                idx = self.data[sym].index
                df_res = pd.DataFrame(index=idx)
                df_res['p_long'] = 0.0; df_res['p_short'] = 0.0; df_res['regime'] = 0
                
                src = self.data[sym]
                for col in ['open', 'high', 'low', 'close', 'atr']:
                    if col in src.columns: df_res[col] = src[col]
                production_data[sym] = df_res

        # –ï—Å–ª–∏ —É–∂–µ –≤—Å–µ –ø–æ—Å—á–∏—Ç–∞–Ω–æ
        if start_idx >= total_steps:
            return

        print(f"üöÄ [FACTORY] –°—Ç–∞—Ä—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {total_steps - start_idx} –Ω–æ–≤—ã—Ö –±–∞—Ä–æ–≤...")
        
        current_idx = start_idx
        pbar = tqdm(total=total_steps - start_idx)
        
        # --- 2. –¶–ò–ö–õ (–¢–æ–ª—å–∫–æ –ø–æ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º) ---
        while current_idx < total_steps:
            # A. TRAIN PHASE
            train_start = max(0, current_idx - window_size - Config.LOOK_AHEAD)
            train_end = current_idx - Config.LOOK_AHEAD 
            
            if train_end > train_start + 500:
                # Parallel Training
                n_cores = max(1, multiprocessing.cpu_count() - 1)
                
                # We pass the EXTERNAL function train_wrapper here
                results = Parallel(n_jobs=n_cores, backend="loky")(
                    delayed(train_wrapper)(
                        sym, 
                        self.models[sym], 
                        self.data[sym].iloc[train_start:train_end], 
                        self.feature_cols
                    ) for sym in self.data
                )

                # Collect results back to main process
                for sym, trained_model in results:
                    self.models[sym] = trained_model
            
            # B. PREDICT PHASE
            test_end = min(total_steps, current_idx + step_size)
            
            for sym in self.data:
                df_full = self.data[sym]
                df_test_chunk = df_full.iloc[current_idx:test_end]
                
                if df_test_chunk.empty: continue
                
                # –í–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–µ–¥–∏–∫—Ç
                probs, regimes = self.models[sym].predict_batch(df_test_chunk, self.feature_cols)
                
                if probs is not None:
                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ production_data
                    # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º .iloc –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏, —Ç–∞–∫ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    # –ù–æ production_data[sym] —ç—Ç–æ –ø–æ–ª–Ω—ã–π —Ñ—Ä–µ–π–º.
                    # –ü—Ä–æ—â–µ —á–µ—Ä–µ–∑ .loc –ø–æ –∏–Ω–¥–µ–∫—Å—É —á–∞–Ω–∫–∞
                    target_idx = df_test_chunk.index
                    
                    production_data[sym].loc[target_idx, 'p_long'] = probs[:, 1]
                    production_data[sym].loc[target_idx, 'p_short'] = probs[:, 2]
                    production_data[sym].loc[target_idx, 'regime'] = regimes

            processed_count = test_end - current_idx
            pbar.update(processed_count)
            current_idx = test_end
            
            # C. INTERMEDIATE SAVE (–ö–∞–∂–¥—ã–µ 5 —à–∞–≥–æ–≤ —Ü–∏–∫–ª–∞ –∏–ª–∏ –≤ –∫–æ–Ω—Ü–µ)
            # –ß—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –ø—Ä–∏ –∫—Ä–∞—à–µ
            # (–î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ–Ω—Ü–µ, –Ω–æ –º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –ø–∞—Ä–∞–Ω–æ–∏–¥–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞)
            # if current_idx % (step_size * 5) == 0:
            #     self._save_to_disk(production_data)

        pbar.close()
        
        # --- 3. –§–ò–ù–ê–õ–¨–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï ---
        self._save_to_disk(production_data)

    def _save_to_disk(self, production_data):
        # –û–±—Ä–µ–∑–∫–∞ "—Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞" (–≥–¥–µ –Ω—É–ª–∏ –≤ –Ω–∞—á–∞–ª–µ —Å–∞–º–æ–º-—Å–∞–º–æ–º)
        # –ï—Å–ª–∏ –º—ã –¥–æ–ø–∏—Å—ã–≤–∞–ª–∏ –∫—ç—à, —Ç–æ –Ω–∞—á–∞–ª–æ —É–∂–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ.
        # –ù–∞–π–¥–µ–º –ø–µ—Ä–≤—É—é –¥–∞—Ç—É, –≥–¥–µ p_long != 0
        
        final_output = {}
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –∏—â–µ–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å —Å –Ω–µ–Ω—É–ª–µ–≤–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é —É –ª–∏–¥–µ—Ä–∞
        master_sym = list(production_data.keys())[0]
        df_master = production_data[master_sym]
        
        # –ë–µ—Ä–µ–º –∏–Ω–¥–µ–∫—Å, –≥–¥–µ –≤–ø–µ—Ä–≤—ã–µ –ø–æ—è–≤–∏–ª–∏—Å—å –¥–∞–Ω–Ω—ã–µ (–∏–ª–∏ –Ω–∞—á–∞–ª–æ –∫—ç—à–∞, –∏–ª–∏ –Ω–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞)
        # –ù–æ —á—Ç–æ–±—ã –Ω–µ —É—Å–ª–æ–∂–Ω—è—Ç—å, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å—ë, –∫—Ä–æ–º–µ –æ—Ç–∫—Ä–æ–≤–µ–Ω–Ω–æ–π –ø—É—Å—Ç–æ—Ç—ã –≤ –Ω–∞—á–∞–ª–µ –∏—Å—Ç–æ—Ä–∏–∏
        
        valid_idx = df_master[(df_master['p_long'] != 0) | (df_master['p_short'] != 0)].index
        if not valid_idx.empty:
            start_date = valid_idx[0]
        else:
            start_date = df_master.index[0]

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ (c {start_date})...")
        
        for sym, df in production_data.items():
            final_output[sym] = df.loc[start_date:]
            
        with open(self.OUTPUT_FILE, "wb") as f:
            pickle.dump(final_output, f)
            
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {self.OUTPUT_FILE}")

    def _merge_with_existing_signals(self, new_signals: dict[str, pd.DataFrame]) -> dict[str, pd.DataFrame]:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç production_signals_v1.pkl —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–∫—É—â–µ–º—É —é–Ω–∏–≤–µ—Ä—Å—É.
        –û—Å—Ç–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤—ã (–¥—Ä—É–≥–∞—è –±–∏—Ä–∂–∞) –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.
        """
        result: dict[str, pd.DataFrame] = {}

        # 1) –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª
        try:
            if os.path.exists(self.OUTPUT_FILE):
                with open(self.OUTPUT_FILE, "rb") as f:
                    old = pickle.load(f)
                if isinstance(old, dict):
                    result.update(old)
        except Exception as e:
            print(f"‚ö†Ô∏è [UNIVERSAL] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")

        # 2) –û–±–Ω–æ–≤–ª—è–µ–º / –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Ç–µ–∫—É—â–µ–≥–æ —é–Ω–∏–≤–µ—Ä—Å–∞
        for sym, df in new_signals.items():
            result[sym] = df

        return result

# =================== –ê–°–ò–ù–•–†–û–ù–ù–´–ô –ò–ù–¢–ï–†–§–ï–ô–° –î–õ–Ø –ù–û–í–û–ì–û –ö–û–î–ê ===================

async def async_main(args):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ GUI / CLI.
    args ‚Äî —É–∂–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π argparse.Namespace
    """
    from config import Config
    from execution_router import ExecutionRouter

    print(f"üöÄ [ASYNC] –ó–∞–ø—É—Å–∫ –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ")
    print(f"   üìä –ë—Ä–æ–∫–µ—Ä: {args.broker}")
    print(f"   üéÆ –†–µ–∂–∏–º: {args.mode}")
    print(f"   ‚öôÔ∏è  –ü—Ä–µ—Å–µ—Ç: {args.preset}")
    print(f"   üß† Cross-asset WF: {'–í–∫–ª—é—á–µ–Ω' if args.cross_asset_wf else '–í—ã–∫–ª—é—á–µ–Ω'}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–æ—É—Ç–µ—Ä –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
    router = ExecutionRouter()
    await router.initialize(broker_name=args.broker)
    
    try:
        # –†–µ–∂–∏–º UNIVERSAL (–ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–æ–∑–≥)
        if args.mode == "universal":
            print("\nüß† [ASYNC] –ó–∞–ø—É—Å–∫ UniversalSignalFactory...")
            
            u_factory = UniversalSignalFactory(
                regime_preset=args.preset,
                cross_asset_wf=args.cross_asset_wf,
                train_window=args.train_window,
                trade_window=args.trade_window,
            )
            
            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
            u_factory.load_data()
            
            # 2. –û–±—É—á–µ–Ω–∏–µ (–µ—Å–ª–∏ –Ω–µ —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å)
            if not args.inference_only:
                print("üéì –û–±—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
                u_factory.run_universal_training()
            
            # 3. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –ø–æ—Ä—Ç—Ñ–µ–ª–µ (–µ—Å–ª–∏ –Ω–µ —Ç–æ–ª—å–∫–æ –æ–±—É—á–µ–Ω–∏–µ)
            if not args.universal_only:
                print("üîÆ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –ø–æ—Ä—Ç—Ñ–µ–ª–µ...")

                try:
                    with open(u_factory.OUTPUT_FILE, "rb") as f:
                        signals = pickle.load(f)
                    
                    # –ê–Ω–∞–ª–∏–∑ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ –≤—ã–±–æ—Ä –ø–æ—Ä—Ç—Ñ–µ–ª—è
                    portfolio_decisions = analyze_portfolio_signals(
                        signals,
                        portfolio_size=args.portfolio_size,
                        risk_level=args.risk_level,
                    )

                    if portfolio_decisions:
                        print(f"\nüìä –¢–æ–ø-{len(portfolio_decisions)} —Å–∏–≥–Ω–∞–ª–æ–≤ –≤—ã–±—Ä–∞–Ω—ã –¥–ª—è –ø–æ—Ä—Ç—Ñ–µ–ª—è.")
                        await router.execute_portfolio_decisions(portfolio_decisions)
                        print(f"‚úÖ –ü–æ—Ä—É—á–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã: {len(portfolio_decisions)} –ø–æ–∑–∏—Ü–∏–π")
                    else:
                        print("‚ÑπÔ∏è –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
                
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")
            
            print("‚úÖ [ASYNC] –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å: –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã")
            
        else:
            # WALK-FORWARD —Ä–µ–∂–∏–º
            print("\nüö∂ [ASYNC] –ó–∞–ø—É—Å–∫ SignalFactory (walk-forward)...")
            
            factory = SignalFactory(
                regime_preset=args.preset,
                force_reset=args.reset,
                train_window=args.train_window,
                trade_window=args.trade_window,
            )
            
            print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
            factory.load_data()
            
            print("üîÑ –ó–∞–ø—É—Å–∫ walk-forward...")
            factory.run_walk_forward()
            
            print("üìà –ê–Ω–∞–ª–∏–∑ —Å–≤–µ–∂–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Ä–¥–µ—Ä–æ–≤...")
            try:
                with open(factory.OUTPUT_FILE, "rb") as f:
                    signals = pickle.load(f)
                
                latest_signals = get_latest_signals(signals)
                orders = prepare_orders_from_signals(
                    latest_signals,
                    risk_level=args.risk_level,
                )
                
                if orders:
                    await router.execute_batch_orders(orders)
                    print(f"‚úÖ –û—Ä–¥–µ—Ä–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã: {len(orders)}")
                else:
                    print("‚ÑπÔ∏è –ù–µ—Ç –æ—Ä–¥–µ—Ä–æ–≤, —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—â–∏—Ö —Ñ–∏–ª—å—Ç—Ä–∞–º –ø–æ —Å–∏–ª–µ —Å–∏–≥–Ω–∞–ª–∞.")
            
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –æ—Ä–¥–µ—Ä–æ–≤: {e}")
            
            print("‚úÖ [ASYNC] Walk-forward –∑–∞–≤–µ—Ä—à–µ–Ω")
            
    except Exception as e:
        print(f"‚ùå [ASYNC] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        await router.close()
        print("üîí [ASYNC] –†–µ—Å—É—Ä—Å—ã –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω—ã")


# =================== –ö–û–ù–ï–¶ –ê–°–ò–ù–•–†–û–ù–ù–û–ì–û –ö–û–î–ê ===================

# ====== –•–ï–õ–ü–ï–†–´ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –°–ò–ì–ù–ê–õ–û–í –ò –ü–û–î–ì–û–¢–û–í–ö–ò –û–†–î–ï–†–û–í ======

def analyze_portfolio_signals(
    signals: dict,
    portfolio_size: int = 10,
    risk_level: float = 0.02,
):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è –ø–æ—Ä—Ç—Ñ–µ–ª—è.
    (–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞)
    """
    decisions = []
    
    for symbol, df in signals.items():
        if df.empty:
            continue
            
        last_row = df.iloc[-1]
        signal_strength = calculate_signal_strength(last_row)
        direction = "BUY" if last_row['p_long'] > last_row['p_short'] else "SELL"
        
        position_size = calculate_position_size(
            symbol,
            last_row.get('atr', 0.01),
            risk_level,
        )
        
        decisions.append({
            'symbol': symbol,
            'direction': direction,
            'strength': signal_strength,
            'size': position_size,
            'timestamp': df.index[-1],
            'p_long': last_row['p_long'],
            'p_short': last_row['p_short'],
            'regime': last_row['regime'],
        })
    
    decisions.sort(key=lambda x: x['strength'], reverse=True)
    return decisions[:portfolio_size]


def calculate_signal_strength(row):
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–∏–ª—É —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ —Ä–µ–∂–∏–º–∞."""
    base_strength = abs(row['p_long'] - row['p_short'])
    
    regime_modifier = {
        0: 0.5,  # –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π
        1: 1.0,  # —Ç—Ä–µ–Ω–¥–æ–≤—ã–π
        2: 0.8,  # –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã–π
        3: 0.6,  # —Ñ–ª—ç—Ç–æ–≤—ã–π
    }.get(row['regime'], 0.5)
    
    return base_strength * regime_modifier


def calculate_position_size(symbol, atr, risk_level):
    """
    –°–ò–ù–•–†–û–ù–ù–´–ô —Ä–∞—Å—á—ë—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ ATR –∏ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ –¥–≤–∏–∂–æ–∫, —á—Ç–æ –∏ –±–æ–µ–≤–æ–π —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç (calc_position_size).
    """
    from data_loader import DataLoader  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–æ–≤

    equity = getattr(Config, "DEPOSIT", 1000.0)
    sl_mult = Config.DEFAULT_STRATEGY.get("sl", 2.0)
    max_notional = getattr(Config, "MAX_POSITION_NOTIONAL", None)

    try:
        end = datetime.now()
        start = end - timedelta(days=1)
        data = DataLoader.get_symbol_data(symbol, start, end, "1h")

        if not data.empty:
            current_price = float(data["close"].iloc[-1])

            # –ï—Å–ª–∏ ATR –≤ —Å–∏–≥–Ω–∞–ª–∞—Ö –Ω–µ –∑–∞–¥–∞–Ω –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω ‚Äî –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º –≥—Ä—É–±–æ.
            if atr is None or atr <= 0:
                atr_value = (
                    data["close"]
                    .diff()
                    .abs()
                    .rolling(14)
                    .mean()
                    .iloc[-1]
                )
            else:
                atr_value = float(atr)

            ps = calc_position_size(
                equity=equity,
                risk_per_trade=risk_level,
                atr=atr_value,
                sl_mult=sl_mult,
                price=current_price,
                max_notional=max_notional,
            )

            if ps.size > 0:
                return ps.size

    except Exception:
        # –í —Å–ª—É—á–∞–µ –ª—é–±–æ–π –æ—à–∏–±–∫–∏ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0 ‚Äî –Ω–µ –ª–µ–∑–µ–º –≤ —Å–¥–µ–ª–∫—É
        return 0.0

    return 0.0

def prepare_orders_from_signals(latest_signals: dict, risk_level: float):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –æ—Ä–¥–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)."""
    orders = []
    
    for symbol, row in latest_signals.items():
        # —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å–∏–ª–µ —Å–∏–≥–Ω–∞–ª–∞
        if row['p_long'] < 0.6 and row['p_short'] < 0.6:
            continue
            
        direction = "BUY" if row['p_long'] > row['p_short'] else "SELL"
        
        size = calculate_position_size(
            symbol,
            row.get('atr', 0.01),
            risk_level,
        )
        
        orders.append({
            'symbol': symbol,
            'side': direction,
            'quantity': size,
            'order_type': 'MARKET',
            'signal_strength': max(row['p_long'], row['p_short']),
        })
    
    return orders


def get_latest_signals(signals: dict):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–∏–≥–Ω–∞–ª—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è."""
    latest = {}
    for symbol, df in signals.items():
        if not df.empty:
            latest[symbol] = df.iloc[-1]
    return latest


if __name__ == "__main__":
    # –ï–î–ò–ù–´–ô –ø–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è sync+async —Ä–µ–∂–∏–º–æ–≤
    parser = argparse.ArgumentParser(description="Signal Factory & ML Trainer")

    # –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument(
        "--preset",
        type=str,
        default="classic",
        choices=["classic", "grinder", "sniper", "loose"],
        help="Market regime preset",
    )
    parser.add_argument(
        "--reset",
        action="store_true",
        help="Force delete cache and recalculate everything (walk mode only)",
    )
    parser.add_argument(
        "--mode",
        type=str,
        default="walk",
        choices=["walk", "universal"],
        help="Signal generation mode: walk (per-symbol WF) or universal (global brain)",
    )
    parser.add_argument(
        "--train_window",
        type=int,
        default=None,
        help="Train window in candles (WF & Universal CA-WF)",
    )
    parser.add_argument(
        "--trade_window",
        type=int,
        default=None,
        help="Trade/OOS window in candles",
    )
    parser.add_argument(
        "--cross_asset_wf",
        action="store_true",
        help="Enable Cross-Asset Walk-Forward for UNIVERSAL mode",
    )

    # –§–ª–∞–≥ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
    parser.add_argument(
        "--async_mode",
        action="store_true",
        help="Run in async mode with GUI support",
    )

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–æ–ª—å–∫–æ –¥–ª—è async-–≤–µ—Ç–∫–∏
    parser.add_argument(
        "--broker",
        type=str,
        default="bitget",
        help="Broker name (async mode only)",
    )
    parser.add_argument(
        "--portfolio_size",
        type=int,
        default=10,
        help="Number of assets in portfolio (async mode only)",
    )
    parser.add_argument(
        "--risk_level",
        type=float,
        default=0.02,
        help="Risk per trade (async mode only)",
    )
    parser.add_argument(
        "--universal_only",
        action="store_true",
        help="Run only universal training (async mode only)",
    )
    parser.add_argument(
        "--inference_only",
        action="store_true",
        help="Run only inference (async mode only)",
    )

    args = parser.parse_args()
    
    if args.async_mode:
        print("üöÄ –ó–∞–ø—É—Å–∫ –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ...")
        asyncio.run(async_main(args))
    else:
        # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–æ–¥
        if args.mode == "walk":
            print(f"\nüè≠ [FACTORY] –ó–∞–ø—É—Å–∫ WALK-FORWARD. Preset: {args.preset.upper()}")
            if args.reset:
                print("‚ö†Ô∏è FORCE RESET: –∫—ç—à —Å–∏–≥–Ω–∞–ª–æ–≤ –±—É–¥–µ—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω.")

            factory = SignalFactory(
                regime_preset=args.preset,
                force_reset=args.reset,
                train_window=args.train_window,
                trade_window=args.trade_window,
            )
            factory.load_data()
            factory.run_walk_forward()
            print("\n‚û°Ô∏è –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: python optimizer.py --mode sniper")

        else:
            print(f"\nüß† [UNIVERSAL] –ó–∞–ø—É—Å–∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –º–æ–∑–≥–∞. Preset: {args.preset.upper()}")
            u_factory = UniversalSignalFactory(
                regime_preset=args.preset,
                cross_asset_wf=args.cross_asset_wf,
                train_window=args.train_window,
                trade_window=args.trade_window,
            )
            u_factory.load_data()
            u_factory.run_universal_training()